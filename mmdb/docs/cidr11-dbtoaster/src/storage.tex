A DDMS is created with knowledge of the workload it will be used for; though the set of transition functions may be infinite, there is a finite set of classes of transition function that we can analyze, not only to simplify incremental computation, but also to streamline the storage mechanisms underpinning the database.

For example, consider a DDMS constructed to maintain a view of the base relations as well as the query\texttt{\\
SELECT prof, COUNT(DISTINCT e.student)\\
FROM Professors p, Classes c, Enrollment e\\
WHERE p.id = c.teacher AND c.id = e.class\\
GROUP BY prof\\
}
Here, \texttt{c.teacher} and \texttt{e.class} are foreign keys mapped to \texttt{p.id} and \texttt{c.id} respectively.  We can implement this query in the DDMS by using two tables: one of students for each professor, and another containing the count of students for each professor.  Though the data is drawn from two distinct logical tables, the most efficient storage mechanism would place the student list on the same page as the student count.

\subsection{Partitioning}
Compared to stream processing systems, DDMSes have much more state, necessitating the use of more intelligent storage techniques.  However, compared to traditional DBMSes, DDMSes have more information to use when constructing a task-specific storage solution.  Regardless of the exact nature of the storage being used: whether it be pages on a disk, disks in a RAID, or servers in a cluster, the DDMS' goal is to select an efficient allocation of data to physical storage units.

The notion of transition functions presents us with a clean mechanism for quantifying the cost (or benefit) of applying a particular partitioning scheme.  Given a specific transition - a parametrized transition function that is - we can quantify not just the cost of a partitioning scheme, but also the cost of further sub-partitioning techniques.  Integrating over the transition function's parameters and all transition functions, we obtain the cost (or benefit) of a partitioning scheme for the entire DDMS.  

For example, in the DDMS example above...
%%%%%%%%%%%% 

\subsection{Datastructures}
Knowing the query allows us to separate data into key columns (ie, columns used in conditionals), and value columns (ie, columns used to compute things).  Ideal datastructure for this approach is a multikey map

multikey map optimizations - iterator indices, simplicity of (horizontal) partitioning.

\subsection{Secondary Storage}
We can subdivide each transition function into a series of subtasks and produce a bipartite directed hypergraph representing the flow of data caused by the transition function.  For the example above, the insertion of a row into the Enrollment table might result in a read on a single entry in the Classes table, and read/writes on an intermediate table representing the students taught by each professor and the Professor's statistics.  This includes three nodes on the left (the tables being read from), two node on the right (the tables being written to), and one edge.

Every time a portion of the database is split into multiple components, nodes on either side of the graph are split into multiple components.  Depending on the workload, zero or more additional edges will also be created, depending on the query.  More importantly, the mechanism by which additional edges are created can be used to inform the partition allocation scheme.  

For example, in the Professor/... query above....  Example based on the fact that we need scan of each professor's students, can access professor directly, 

1-par implementation of secondary storage optimization: minimize # of unbound edge reads (ie, find me whether or not students are present)

1-par implementation of distributed optimization: minimize # of cross-partition edges

%In keeping with the DDMS' update-centric view of the world, we view each transition function as a series of write operations, each of which may require one or more read operations.  Both read and write operations may operate on a single row, or iterate over all rows in the table matching a selection predicate.  We can construct a directed hypergraph out of the write operations, with each node representing a table, each out-edge representing a read, and each in-edge representing a write.  We refer to this hypergraph as the transition function's data-flow graph.
%
%This data-flow graph provides a useful mechanism for analyzing the storage, processing, and IO requirements of a query.  In particular it simplifies the analysis of schemes that partition data across multiple physical units, be they disk blocks, disks, or storage servers.  
%
%Regardless of the partitioning scheme selected, each table partitioning will introduce new nodes and edges into the data-flow graph.  Based on the query involved, we can accurately predict how many and which new edges will be introduced.  From this point, we can allocate graph nodes to each partition; 
%
%
%From this point, the partitioning problem begins to resemble a weighted set-cover problem; .  Separating 
%Consider a horizontal partitioning scheme.  Table partitions introduce new nodes and edges into the dataflow graph; we can 
%
%As we partition each table into multiple components, we introduce new nodes and edges into the dataflow graph.  
%
%For example, consider a simple database transition function that emulates the following query\texttt{\\
%INSERT INTO T(a,c')\\
%SELECT a, SUM(c)\\
%FROM R(a,b), S(b, c)\\
%WHERE R.b = S.b\\
%GROUP BY a\\
%}
%
%  partitioning the state of the database 
%This transition function consists of a single hyperedge with two inputs and one output.  The input tables are already narrow, so when, we consider only horizontal partitioning.  We can use the dataflow graph to 
%
%If it becomes necessary to partition the state of the database across multiple disk blocks, disks, or storage servers, we can use the , we could store the entire 
%
%reads from two tables and writes to a third.  This transition function's dataflow graph has a single directed hyperedge with two inputs and one output.  The first reader reads a single 
%
%\begin{itemize}
%\item Overview of read, write, and message costs
%
%\item Partitioning across multiple axis, expanding the dataflow graph into a messaging graph.  
%
%\item Messaging and computational (memory) resources, separability of subgraphs.
%
%\item Basic instantiation - 1 disk or cluster
%
%\item Extensions to the multi-disk case
%\end{itemize}