Given a database, existing view maintenance techniques incrementally handle
transitions to another state for a given update. We can informally represent the
database state as a triple $\tuple{q,m,q'}$, corresponding to the view query,
the materialization of that query, and the delta query responsible for
maintaining the materialization respectively. The delta query $q'$ can be
thought of as a parameterized SQL query, with parameters corresponding to
attributes of an update to a delta table. On an update $u$, incremental view
maintenance (IVM) performs the work: $m \mbox{ {\tt+}= } q'(u)$. That is a
materialized view can be updated with the result of a delta query taking
parameters from $u$, and this must ensure $m = q(db_{new})$, where $db_{new}$ is
the result of applying the update to the database.

\subsection{View Maintenance in DBToaster}
DBToaster makes the following key insight regarding the transitions performed by
IVM: current IVM performs much redundant work, since for each transition a delta
query $q'$ will access all base tables except for the delta table, and processes
these tuples from scratch, \textit{even if there is no change to any of these
other base tables}. DBToaster materializes the result of the delta query and
reuses it upon repeated updates to the delta table. The materialized delta query
is be added to the database state, and we can write this as $\tuple{q',m',q''}$.
This leads to the concept of higher-order deltas, such as $q''$ which is a
second-order delta query. This process can \textit{recur}, we can materialize
$q''$ as $m''$, maintain with $q'''$ and so forth.

Recursive delta query materialization does not continue forever and terminates
given one important property of computing delta queries: \textit{a delta query
is often simpler than its parent query}. In particular \textit{k}-th order delta
query, $q^k$ has fewer input relations than a \textit{k-1} order query
$q^{k-1}$, but additional parameters corresponding to attributes that are
present in $q^{k-1}$.

\tinysection{Compilation example}
We present an example of this recursive materialization or \textit{delta query
compilation} approach on a query similar to TPC-H Query 3:

\def \ql#1{{\tt #1}}
\hspace{-6mm}
\begin{tabular}{ll}
$q =$ & \ql{select\ \ \ l.ordkey, o.sprior, sum(l.extprice)}\\
      & \ql{from\ \ \ \ \ customer c, orders o, lineitem l}\\
      & \ql{where\ \ \ \ c.custkey = o.custkey}\\
      & \ql{and\ \ \ \ \ \ l.ordkey = o.ordkey}\\
      & \ql{group by l.ordkey, o.sprior;}
\end{tabular}


\noindent Let us denote this query as $q$, and its materialization $m$.
Technically $m$ has result schema {\tt ordkey, sprior} and an unnamed
aggregate value. We represent our materialized views as map datastructures, and
denote this by \linebreak $m[ordkey, sprior]$. In this case the map's key
corresponds to group-by attributes and the map's value is the unnamed aggregate
value. We can answer the query by iterating over all entries in $m$, and
yielding aggregate values.

\comment{
We represent our materialized views as map datastructures, and
denote this by a two-level map $m[][ordkey, sprior]$. Since we materialize
delta queries, which are parameterized SQL queries, the first level of our maps
corresponds to parameters, while the second level to the query's result schema.
In this case the map's second level key corresponds to group-by attributes and
the map's value is the unnamed aggregate value. Thus we can answer the query by
iterating over all entries (group-by values) in map $m$, and yielding each
aggregate value.
}

We can take the delta (as defined in existing IVM literature
[REFs]) of an insertion, {\tt +c(ck,nm,nk,bal)} to the {\tt customer} relation,
to produce a first-order delta query:


\hspace{-6mm}
\begin{tabular}{ll}
$q' =$  & \ql{select\ \ \ l.ordkey, o.sprior,sum(l.extprice)}\\
        & \ql{from\ \ \ \ \ orders o, lineitem l}\\
        & \ql{where\ \ \ \ @ck = o.custkey}\\
        & \ql{and\ \ \ \ \ \ l.ordkey = o.ordkey}\\
        & \ql{group by l.ordkey, o.sprior;}
\end{tabular}

\noindent The above is a parameterized SQL statement with {\tt @ck} a parameter
that is filled in by the update {\tt +c(ck,nm,nk,bal)}. We write its
materialization as $m'[ck,ordkey,sprior]$, where $m'$ has an additional
attribute in its key for parameter $ck$. To maintain $m$ on insertion {\tt
+c(ck,nm,nk,bal)}, we must evaluate $q'(\mbox{{\tt ck}})$, the delta query $q'$
with parameter {\tt ck}. We do this via a map lookup of
$m'[\mbox{{\tt ck}},ordkey,sprior]$. Now, the astute reader may ask where
do the values of $ordkey$, $sprior$ come from in this lookup? Recall that
to answer $q$, map $m$ maintains aggregates for every $ordkey$, $sprior$
combination in the update stream. Thus $m'$ also maintains every
$ordkey$, $sprior$ combination. We iterate over every entry to maintain
$m$ from $m'$. The maintenance statement in the transition
program for {\tt customer} is:

\begin{verbatim}
on_insert_customer(ck,nm,nk,bal):
  for each ordkey,sprior in m:
    m[ordkey,sprior] += m'[ck,ordkey,sprior];
\end{verbatim}

\noindent We need not explicitly represent the for loop above. Observe that
neither $ordkey$ nor $sprior$ are part of the function's arguments. We
consider variables not occuring in arguments to implicitly require loops over
the map appearing on the left hand side of a map update statement. The above
becomes:

\begin{verbatim}
on_insert_customer(ck,nm,nk,bal):
  m[ordkey,sprior] += m'[ck,ordkey,sprior];
\end{verbatim}

\noindent Alternatively, we could have started with delta queries for insertions
to {\tt order} or {\tt lineitem}. Due to space limitations, we omit their
compilation. Indeed, we must be able to handle any transition, thus
for full, correct, incremental maintenance, we compile for all 
possible combinations of insertions and deletions. We show the full transition
program for insertions at the end of the example.

We now incrementally maintain $m'$, say on insertion {\tt +l(ok,ep)} with a
second-order delta query:

\hspace{-6mm}
\begin{tabular}{ll}
$q'' =$  & \ql{select\ \ \ @ok, o.sprior,sum(@ep)}\\
         & \ql{from\ \ \ \ \ orders o}\\
         & \ql{where\ \ \ \ $ck$ = o.custkey and @ok = o.ordkey}\\
         & \ql{group by o.sprior;}
\end{tabular}

\noindent This delta removes {\tt l.ordkey} as a group-by attribute,
since the update only affects a single group given by the value of parameter
{\tt @ok}. Furthermore, since we are summing up a parameter {\tt @ep}, we can
apply distributivity laws of sum aggregates and rewrite this to:

\hspace{-6mm}
\begin{tabular}{ll}
$q'' =$  & \ql{select\ \ \ @ok, o.sprior,@ep*count()}\\
         & \ql{from\ \ \ \ \ orders o}\\
         & \ql{where\ \ \ \ $ck$ = o.custkey and @ok = o.ordkey}\\
         & \ql{group by o.sprior;}
\end{tabular}

\noindent Above, we use $ck$ to distinguish parameters that are part of some map
key, and parameters that are part of the update such as {\tt @ok}. The parameter
$ck$ originates from {\tt c.custkey} in $q$, so map key components can be
passed through multiple levels of compilation. We materialize $q''$ as
$m''[ck,ok,sprior]$ and produce the maintenance statement:

\begin{verbatim}
on_insert_lineitem(ok,ep):
  m'[ck,ok,sprior] += ep * m''[ck,ok,sprior];
\end{verbatim}

\noindent Finally, we can take the delta of an insertion {\tt +o(ck,ok,sp)} to
maintain $m''$:

\hspace{-6mm}
\begin{tabular}{ll}
$q''' =$  & \ql{select\ \ \ @sp,count()}\\
          & \ql{where\ \ \ \ $ck$ = @ck and $ok$ = @ok;}
\end{tabular}

\noindent Again we remove the group-by clause since we only update the group
{\tt @sp}. This delta query is the terminal point of recursive compilation,
since we have replaced all relations with updates. This query yields a scalar
value of 0-1 based on whether the parameters in {\tt +o(ck,ok,sp)} satisfy the
predicate, as we loop over the entries of the map to be maintained, namely
$m''$. The maintenance statement is:

\comment{
\begin{verbatim}
on_insert_order(ck,ok,sp):
  m''[ck',ok',sp] +=
    if ck'==ck and ok'==ok then 1 else 0
\end{verbatim}

\noindent This can be simplified by noting that only a single entry is
incremented by a non-zero value, yielding:
}

\begin{verbatim}
on_insert_order(ck,ok,sp): m''[ck,ok,sp] += 1
\end{verbatim}

\noindent Our compilation algorithm considers all possible update orders, and
materializes each delta query encountered. We detect and reuse duplicate maps
based on equivalent delta queries. The full transition program, with $m' =
m\_c$, and $m''=m\_cl$ is:

\begin{verbatim}
on_insert_customer(ck,nm,nk,bal) :
  m[ordkey, sprior] += m_c[ck, ordkey, sprior];
  m_l[ordkey, sprior] += m_cl[ck, ordkey, sprior];
  m_o[ck] += 1;

on_insert_lineitem(ok,ep) :
  m[ok, sprior] += ep *  m_l[ok, sprior];
  m_c[custkey, ok, sprior] +=
    ep *  m_cl[custkey, ok, sprior];
  m_co[ok] += ep;

on_insert_order(ck,ok,sp) :
  m[ok, sp] += m_co[ok] * m_o[ck]; 
  m_l[ok, sp] += m_o[ck];
  m_c[ck, ok, sp] += m_co[ok];
  m_cl[ck, ok, sp] += 1;
\end{verbatim}

\tinysection{Transition Program Properties}
For many queries, compilation to transitions yields \textit{simple} code, that
has no join trees, and at most single-level for loops (no nested loops), that
are essentially performing probing as found in hash joins. The transition
program is also exploiting distributivity to push down aggregates through joins,
yielding small map sizes since maps maintain group-by (partial) aggregates. We
believe simple code is beneficial for analysis and optimizations as part of
low-level compilation and code generation.

Transition programs lean on the side of trading off space for time. They
construct and maintain auxiliary state, requiring more space. These space
requirements are dependent on the active domain sizes of attributes, and often
attributes do not have many distinct values, for example stock identifiers in
order books, where there are approximately 2,800 listings in NASDAQ, NYSE.
Furthermore checking for duplicate maps finds many opportunities to reuse
materialization given compilation with all permutations of deltas. Finally,
there are numerous design choices and optimizations available to vary space-time
requirements for transitions. We need not materialize all higher-order deltas.
For example we could maintain $q$ with $m^i$, a materialized $i$-th order delta
and perform more work during the update to evaluate $q^{i-1}, \ldots, q^1$. We
could further amortize space by exploiting commonality across multiple queries,
merging maps to service multiple delta queries.



\tinysection{Insights} We highlight a few insights drawn from our experience in
several iterations of designing the algorithm. Compiling the transition function
for view maintenance is advantageous and feasible (in that it terminates) due to
the property that higher order delta queries successively get simpler and
simpler. The terminal delta consists of parameters alone, and does not depend on
the database. Materializing higher order deltas yields continuous query
evaluation that is \textit{as incremental as possible}.

Queries are closed under taking deltas, that is a delta query is of the same
language as the parent query. In the above example, we have materialized all
deltas, thus the transition program consists of simple arithmetics on parameters
and map lookups. In general, closed deltas mean that evaluating delta queries
requires a relational query engine. This could be done with an existing DBMS
kernel, but we believe we can innovate in the design of main-memory query
processors and briefly touch on this following section.

Finally, our concept of higher-order deltas draws novel, natural analogies to
concepts in mathematics. We have a rich formal framework, partially described in
[PODS REF], where queries are represented as polynomials, admit transformations
compactly represented by an algebraic structure, namely rings, and demonstrates
that the degree of the polynomial is reduced under taking deltas, much like
derivatives in calculus.

\tinysection{Discussion}
\begin{itemize}
  \item \todo{Nowhere do you mention that this applies to aggregate queries
  alone. We can do non-aggregation queries but then main-memory becomes an
  issue. We don't see an as much of an advantage, the really strong case is for
  queries with aggregates.}
  \item Comparison to today's IVM
  \item Relationship to GDL
  \item Eddies
\end{itemize}

\subsection{Compilation Enhancements}
\noindent We presented our compilation above using a fairly simple query example
consisting of only equi-joins, illustrating compilation for insertions.
Now, we briefly discuss further compilation issues and optimizations.

\tinysection{Deletions}
Our example above only mentions inserts, but handling deletions turns out to be
straightforward. Our framework represents both the database and queries entirely
as maps\footnote{We have toyed with calling our system a MapStore, but prefer a
name with mystique, DBToaster.}, including base relations. Base relations are
multisets, or, maps with keys according to the relation's schema and values from
tuple's cardinalities, e.g. a tuple $\tuple{a=3,b=5}$ occurring three times in
relation $R(a,b)$ is a map entry $m[3,5] \mapsto 3$. Deletions are simply tuples
with negative multiplicities, and are implemented in their own transition
function.

\tinysection{Simplifying Delta Queries}
Transition compilation internally uses several techniques to simplify queries
as we are taking deltas. We present two of these here, starting with
unification leading to variable elimination. Consider the SQL query:
\begin{verbatim}
select sum(l.extendedprice) from partsupp ps, lineitem l
where @pk = ps.partkey and ps.partkey = l.partkey
      and ps.suppkey = l.suppkey and l.quantity < 10
\end{verbatim}
By unifying the parameter {\tt @pk}, \todo{finish, needs a better example\ldots} 

The second simplification is factorization. Consider the query:
\texttt{select sum(c.acctbal*(l.extprice-l.discount))
from customer c, lineitem l}.
We can write this as a product of two separate, simpler, aggregates:
\begin{verbatim}
(select sum(c.acctbal) from customer c) * 
(select sum(l.extprice-l.discount) from lineitem l)
\end{verbatim}

\noindent and independently compute deltas for each aggregate. Factorization is
frequently possible when considering star schemas in analytics applications, and
generalizes to structural decompositions, such as hypertree decomposition
\todo{[REF Gottlob]}. While there has been much work in decomposing join
hypergraphs, applying similar techniques to aggregates is an interesting
direction of future work.

\tinysection{Nested Queries}
We can compile transitions for nested queries, which to the best of our
knowledge, has not been feasible in existing IVM techniques. In particular
nested scalar subqueries used in predicates are difficult, because taking deltas
of such predicates does not result in simpler expressions (and thus our
algorithm would not terminate if we did not explicitly handle this). The
\todo{Q-VWAP} query in Section \todo{[REF]} is an example of a nested query.

Nested subqueries contain correlated attributes (e.g. \todo{price in Q-VWAP})
defined from a query in an outer scope. We can treat these correlated attributes
as parameters. While we've presented this discussion in terms of parameterized
queries for ease of understanding through familiarity, our framework internally
treats parameters through binding patterns (indicating bound and free variables)
for queries. In particular, nested queries induce \textit{binding propagation},
similar to sideways information passing in datalog. That is, we support the
results of one query being used (or \textit{propagated}) to the parameters of a
correlated subquery, indicating an ordered evaluation of queries.

As an optimization, compilation transforms queries to use minimal propagation of
variables, which performs additional aggregation of maps, over the dimension of
the map key that is not propagate. For example a map $m[x,y,z]$ would be
aggregated to $m'[x,y]$ if $x,y$ were the only correlated attributes.
Furthermore during compilation, because the delta for a predicate is not simpler
than the predicate, to ensure compilation terminates, we explicitly find simpler
terms and recur on them. This only happens for nested queries in constraints,
the remainder of the language is handled as in our example.



\comment{
\tinysection{Initial values}

\tinysection{Windows, Constraints, Other Aggregates}
\begin{itemize}
  \item Do you really want to include this section? What do you have to say
  that's strong here \note{i.e. what can you say about compiling to specific
  datastructures beyond maps?}
  \item Our model of transitions generally addresses the issues of incremental
  processing and can handle stream processing features such as windows.
  \item In fact we can exploit additional schema information such as
  key/foreign-key relationsips, integrity constraints and so forth to further
  simplify our programs. \note{Give simple example with an integrity
  constraint, i.e. we can avoid generating a statement if we know an entry
  cannot exist in another relation due to integrity.}
  \item Min/max handling. The hard case is deletion, since we have to recompute
  from scratch. Our compilation framework uses a query representation where
  everything is a map, including base tables. Thus we can easily express
  materializing relations in addition to group-by aggregates, requiring no
  change to handle other aggregates. This also applies to queries without
  aggregation, for example a SPJ query. \footnote{We have toyed with calling our
  system a MapStore, but prefer a name with mystique, DBToaster.}
\end{itemize}
}



\tinysection{Towards Optimizing Engine Physicality}
Our implementation of delta queries uses a functional programming approach,
where we can apply techniques from structural recursion \todo{[REF Kleisli]},
prior to generating low-level code. Structural recursion enables optimizations
of arbitrarily nested collections such as sets, bags and lists, and is our basis
for enabling programmatic representation and manipulation of numerous
\textit{physical-level plan properties}, such as tuple construction and
pipelining.

Delta queries consist of cross products and joins of many maps, due to
factorization of, and binding propagation in queries. In a traditional DBMS
engine treats, cross products and join operators work on relations, to produce
relations, ``flattening'' intermediate results into rows. Column-stores have
argued for the late materialization of tuples \todo{[REF: Abadi ICDE 2007]}. We
produce intermediate results in a general nested form (cf. nested relations and
objects) which may include multiple levels of nesting after combining several
maps. Then, we can exploit structural recursion which critically makes use of
function composition and inlining, to programmatically control where, and how
much tuple construction we perform.

Function composition and inlining also lets us entirely avoid constructing
\textit{any} intermediate results, let alone worry about flattening
intermediates. This enables \textit{automatic} transformation of a join-tree
into an n-way multijoin, which, for example, for a series of cross products
would yield an n-level pipelined nested loops implementation that avoids
expensive intermediates. Furthermore we can explore a much richer space of join
plans by enabling varying operator in-degrees. To the best of our knowledge,
DBToaster would be the first query processor to incorporate automated,
programmatic manipulation of physical aspects of plans, since we reason about
query processing from a data structure perspective, not an operator abstraction
that hides and encapsulates data structures. Our techniques will be equally
applicable to main-memory query processing beyond a DDMS, since our delta
queries are the same as standard SQL queries.



%%%%%%%
%%
%% OLD
\comment{
We present an example of designing a transition function between database
states, in this case focusing on dynamic data driving view maintenance of
standing queries comprising the visible schema. The underlying conceptual model
of a database management system as a state machine has driven our prior work on
this topic in the DBToaster project [REFS], and here we discuss how the concept
of transitioning entire database states has led to a novel view maintenance
algorithm. Furthermore the need to apply this transition with high frequency
motivates precomputing and compiling the transition function into extremely
efficient code.

This section is intended to convey that our database-as-state model can lead to
significant rethinking of existing methods throughout a data management system,
and novelty, algorithmically and architecturally, in designing a system to
handle dynamic data. Throughout this section, we use the term transition to
refer to both the update itself, and the work required to evolve the database
following the application of the update to base tables.

\vspace{1mm}
\subsection{View Maintenance in DBToaster}
Given a database state, existing view maintenance techniques will incrementally
handle transitions to another state for a given update. We can informally
represent this with a triple $\tuple{q,m,q'}$, corresponding to the view query,
the materialization of that query, and the delta query responsible for
maintaining the materialization.
\note{Should talk more about delta queries if you're going to make this the
first mention of it, i.e. with an example}
On an update, view maintenance performs the work: $m_{new} = m_{old} + q'(u)$,
and this is guaranteed to ensure $m_{new} = q(db_{new})$. That is, a
materialized view can be updated with the result of a delta query taking an
update $u$ as an argument, and the view maintenance technique must ensure the
updated view is equivalent to the query result on the modified database. Here,
the delta query can be thought of as a parameterized SQL query, with parameters
corresponding to attributes in the update.

With our conceptual model, we are able to make the
following key insight when taking a holistic approach with the state machine
model, namely that repeatedly applying the same transition with current
techniques results in significantly redundant work. While a transition results
in incremental processing in terms of the part of the database affected by the
update, it is not incremental with respect to the remainder of the database. The
transition evalutes delta queries from scratch on the remainder of the database,
rather than leveraging the fact that this remnant has not changed, and any work
done previously on that portion of the database can be reused.
\note{Diagram here:
\comment{states containing base relations and a query,
transitions for all base relations, each leading to another state. For one of these
neighboring states, we'll repeatedly apply the same transition, highlighting
that the remainder of the base tables do not change, yet the delta queries are
still evaluated from scratch.}
}

To facilitate reuse, we materialize the delta query over the remainder tables,
making it part of the auxiliary state of the database. We refer to this as the
view state, and it is used in our view maintenance approach. Subsequently our
transitions must maintain the view state, leading to the concept of higher-order
delta queries. Higher-order deltas are determined through a recursive processing
of materializing a delta query, and then incrementally maintaining the
materialized result (which would involve further materialization, and delta
queries and so on). That is we can define further triples,
$\tuple{q', m', q''}$, corresponding to the delta query, its materilization,
and a second-order delta query, and so on with $\tuple{q'',m'',q'''}$.
\note{Diagram here.}

This process does not continue forever and terminates given one important
property of computing delta queries: \textit{a delta query is often simpler than
its parent query}. In particular \textit{k}-th order delta query, $q^k$ has
fewer input relations than a \textit{k-1} order query $q^{k-1}$, but additional
parameters corresponding to attributes that are present in $q^{k-1}$. This
provides an informal overview of our view maintenance approach, and we present
an algorithm below to compute both the view state being materialized and the
higher-order delta queries that maintains the view state. The algorithm yields a
\textit{transition program}, essentially trigger function that efficiently
executes a transition from one database to another, including both the visible
and auxiliary state. For the view maintenance problem, the transition program is
simply a sequences of updates to materialized views by delta queries, each
update being of a different order.

\vspace{1mm}
\subsection{Compiling Queries to Transition Programs}
\noindent To present our algorithm, we first describe our query representation,
tailored for incremental processing, and a simple and powerful set of transformations
that we use to simplify and optimize queries.

\tinysection{Query Language}
\noindent Our query language is described by the following EBNF:

\def \calcsum{\mbox{Sum}}
\def\calceq{\mbox{{\tt =}}}
\def\calcgt{\mbox{{\tt >}}}
\def\calcgte{\mbox{{\tt >=}}}
\def\calclte{\mbox{{\tt <=}}}
\def\calclt{\mbox{{\tt <}}}

\def \q{q}
\def \qa{q_1}
\def \qb{q_2}
\def \v#1{\mbox{#1}}
\def \vv#1{\mbox{{\tiny #1}}}
\def \z{\mathbb{Z}}

\vspace{-3mm}
\begin{align*} 
\q \; \mbox{::-} &
  \;    c \;|\; x
  \;|\; R(\vec{x}) \;|\; m(\vec{x},\vec{y})
\\
| & \; \calcsum(\vec{x}, \q)
  \;|\; \q + \q \;|\; \q * \q  \;|\; -\q
  \;|\; \q \; \theta \; 0 \;|\; x := \q
\end{align*}

The grammar represents basic terms of queries such as constants, variables, and
relations $R$ (with attributes $\vec{x}$). We represent materialized views, $m$,
and refer to them as \textit{maps} since these are the underlying in-memory data
structures. Materialized views, or maps, are parameterized SQL queries that
accept parameters $\vec{x}$, and yield schema $\vec{y}$.
Specifically, a map is a \textit{materialized} parameterized query,
where we materialize for all parameter values seen during continuous query
execution (the \textit{active domain} of the parameter).
The intuition behind the representation of views as parameterized SQL comes from
our need to materialize delta queries, which have parameters according to the
update they handle.

For complex terms, the grammar captures sum aggregates
$Sum(\vec{x},q)$ with group-by attributes $\vec{x}$, three generalized
arithmetic operators, addition, multiplication and additive inverse, a
comparison operator ($\theta \in \{=,\neq,<,\leq,>,\geq\}$), and variable
assignment ($:=$). For readability, we write $\calcsum(\q)$ if an aggregate
has no group-bys, and simplify the syntax of comparison as $\theta(\q)$ since
the RHS is 0. 
Our language is quite rich, for example it can represent nested scalar
queries such as the VWAP query in Section [REF]:

\comment{
\begin{verbatim}
select sum(price * vol) from bids b0
where 0.25 * (select sum(b1.vol) from bids b1) >
     (select sum(b2.vol) from bids b2
      where b2.price > b0.price)
\end{verbatim}
}

\vspace{-3mm}
\begin{align*}
\calcsum(
& B(\v{P0,V0}) * \v{P0} * \v{V0} *\\
& \calcgt(0.25 * \calcsum(B(\v{P1,V1}) * \v{V1}) \\
& \qquad \; \; - \calcsum(B(\v{P2,V2}) * \v{V2} * \calcgt(\v{P2-P0}))))
\end{align*}

We briefly discuss expression semantics, starting with maps. Strictly speaking,
\textit{all of the expressions in our grammar (i.e. queries) represent maps},
and maps associate keys to values. Recall our analogy between maps
$m(\vec{x},\vec{y})$ and parameterized SQL queries. Map $m$ has a key
$\tuple{\vec{x},\vec{y}}$, namely the parameters (bound variables, which must be
provided when evaluating a parameterized query) and schema attributes (free
variables, returned by the query). For readability, we use a doubly-indexed map
notation, $m[\vec{x}][\vec{y}]$, instead of writing in pair notation throughout
$m[\tuple{\vec{x}, \vec{y}}]$. We define map values with a generalized multiset
relation [PODS REF] model of a database, where a relation $R$ is a map whose
value yields the cardinality of that tuple in a multiset.

We assume that the user queries provided as input to compilation contain no
maps, only relations and other terms as is standard in SQL. Our compilation
algorithm rewrites queries to include maps. Due to space constraints, we focus
on two arithmetic operations, addition and multiplication. First, we present an
example of addition:

\begin{figure}[h]
\begin{minipage}{1in}
\[
\begin{array}{ll|ll|l}
\multicolumn{5}{c}{m1}\\
 a & c & b & d & \\
\hline
 1 & 1 & 2 & 1 & 3 \\
\comment{
 1 & 2 & 4 & 2 & 1 \\
 1 & 2 & 3 & 3 & 4 \\
}
 1 & 2 &   & 4 & 2
\end{array}
\]
\end{minipage}
+
\begin{minipage}{0.85in}
\[
\begin{array}{ll|l|l}
\multicolumn{4}{c}{m2}\\
 a & c & d & \\
\hline
 1 & 1 & 1 & 1 \\
 1 & 2 & 4 & 2 \\
\end{array}
\]
\end{minipage}
=
\begin{minipage}{1in}
\[
\begin{array}{ll|ll|l}
\multicolumn{5}{c}{m1 + m2}\\
 a & c & b & d & \\
\hline
 1 & 1 & 2 & 1 & 3 \\
 1 & 1 &   & 1 & 1 \\
\comment{
 1 & 2 & 4 & 2 & 1 \\
 1 & 2 & 3 & 3 & 4 \\
}
 1 & 2 &   & 4 & 4
\end{array}
\]
\end{minipage}
\end{figure}

\noindent \note{Above/below}, we have two maps $m1, m2$, where blanks in columns
represent \textit{holes}. Holes are not the same as nulls, they determine when attributes
can be ignored for consistency across tuples.
\note{Explain consistency.}
Addition is a schemaless union where the result contains the union of
operand maps' parameters and result schemas, and adds the values of map entries.

Next, we discuss multiplication. Multiplication is the key
connective in our language since it performs binding propagation, similarly to
datalog, where one map's result schema contains attributes used for
another map's parameters, as seen in $m1[a][b1,b2] * m2[b2,c][d]$.
Here, $b2$ is propagated from map $m1$ to $m2$. The result of this
operation ensures consistency of $b2$ between maps $m1, m2$ (inconsistent
tuples are not included in the output), for example:

\vspace{-4mm}
\begin{figure}[h]
\begin{minipage}{1in}
\[
\begin{array}{l|ll|l}
\multicolumn{4}{c}{m1}\\
 a & b_1 & b_2 & \\
\hline
 1 & 2 & 4 & 3 \\
 2 & 4 & 1 & 1 \\
 2 & 3 & 2 & 4
\end{array}
\]
\end{minipage}
*
\begin{minipage}{0.85in}
\[
\begin{array}{ll|l|l}
\multicolumn{4}{c}{m2}\\
 b_2 & c & d & \\
\hline
 1 & 1 & 1 & 1 \\
 2 & 2 & 4 & 2 \\
\end{array}
\]
\end{minipage}
=
\begin{minipage}{1in}
\[
\begin{array}{ll|ll|l}
\multicolumn{5}{c}{m1 * m2}\\
 a & c & b_1 & d & \\
\hline
 2 & 1 & 4 & 1 & 1 \\
 2 & 2 & 3 & 4 & 8 \\
\end{array}
\]
\end{minipage}
\end{figure}

\vspace{-3mm}
\noindent Above, $b2$ is excluded from the result key since it is a propagated
attribute. The tuple $\tuple{a=1,b1=2,b2=4 \mapsto 3}$ in $m1$ does not
contribute to the result since there is no consistent value of $b2$ in $m2$.
Multiplication is a generalized equi-join, and in the absence of any
propagation, a generalized Cartesian product that operates on both levels of
maps.
\todo{Explain variables, i.e. we don't materialize attributes but these are
bound from the left.}
Binding propagation is critical for a few reasons: i) for
multiplication with variables, it allows a map's values to be combined with the
variable's value; ii) for multiplication with constraints, it yields maps
with 0-1 values indicating whether entries pass the constraint; iii) for
multiplication with other maps, where it facilitiates equi-joins and correlated
attributes in nested queries.


\comment{
We write these semantics as
$R := \tuple{} \mapsto \vec{x} \mapsto R(\vec{x})$, indicating the map has a key
with no parameters, schema $\vec{x}$, and value given by the cardinality $R(x)$
of the multiset $R$. The \textit{type} of the map is
$R : \tuple{} \mapsto \vec{x} \mapsto \z$, thus the semantics indicates the
result key, and the map value.

The semantics of constants and variables are: $c := \tuple{} \mapsto
\tuple{} \mapsto c$ and $Var(x) := \vec{b} \mapsto \tuple{} \mapsto \vec{b}(x)$.
The latter states that variables get their value from query parameters.
Due to space constraints, we briefly present the semantics of complex terms.


\vspace{-4mm}
\begin{align*}
\calcsum(\vec{y}, \q[\vec{x}][\vec{y}\vec{z}]) := & \;
\vec{x} \mapsto \vec{y} \mapsto \sum_{\vec{z}} \q
\\
\qa[\vec{u}][\vec{v}] + \qb[\vec{w}][\vec{x}] := & \;
\vec{y} \mapsto \vec{z} \mapsto
\qa[\vec{y}][\vec{z}] + \qb[\vec{y}][\vec{z}]
\\
& \mbox{ where $\vec{y} = \vec{u} \cup \vec{w}, \vec{z} = \vec{v} \cup \vec{x}$}
\\
-\q[\vec{x}][\vec{y}] := & \; \vec{x} \mapsto \vec{y} \mapsto -(\q)
\\
\q[\vec{x}][] \; \theta \; 0 := & \; \vec{x} \mapsto \tuple{} \mapsto
                    \begin{cases}
                    1 \ldots \q \; \theta \; 0\\
                    0 \ldots \mbox{otherwise.}
                    \end{cases}
\\
(x := \q[\vec{b}][]) := & \; \vec{b} \mapsto \tuple{x=q} \mapsto 1
\end{align*}

Above, we write typing constraints of subexpressions on the left-hand
side of semantics definitions. Thus a sum aggregate with group-by $\vec{y}$
over a map $q[\vec{x}][\vec{yz}]$ adds up values of $\vec{z}$. 
\note{Talk about consistency.}
The addition operator ($+$) is a schemaless union over both parameters and
result schema of its inputs. Additive inverse simply negates the map value,
preserving its type. Predicates yield maps with 0-1 values, and are constrained
to have no output schema. They are singletons, just like constants and
variables, and in this way, our language supports nested scalar queries such as
nested sum aggregates. Finally variable assignment $x := q$ yields a singleton
map with schema $x$, and key (of value) $q$. This leaves the multiplication
operator, which in our langauge is capable of propagating parameters, much like
datalog. Suppose we have: $\qa[\vec{u}][\vec{v}] * \qb[\vec{w}][\vec{x}] :=$

\vspace{-4mm}
\begin{align*}
& \vec{y} \mapsto
\sum_{\{y\} = \{u\} \Join \{w\}} 
\vec{z} \mapsto
  \sum_{\{z\} = \{v\} \Join \{x\}}
  \qa[\vec{y}][\vec{z}] * \qb[\vec{y}][\vec{z}]
\\
& \ldots \mbox{when $\vec{v} \cap \vec{w} = \emptyset$}
\\
& \vec{y} \mapsto
\sum_{\{y\} = \{u\} \Join \{b\}} 
\vec{z} \mapsto
  \sum_{\{z\} = \{v\} \Join \{ax\}}
  \qa[\vec{y}][\vec{z}] * \qb[\vec{y}][\vec{z}]
\\
& \ldots \mbox{otherwise, where $\vec{v} \cap \vec{w} = \vec{a}, 
\vec{w} - \vec{v} = \vec{b}$}
\end{align*}

Above, the first case describes when no propagation occurs. The result map has
parameters and schema according to the join of the operands' keys and value as a
product of operand values. In the second case we have propagation of the LHS
query's result schema being bound as parameters in the RHS query. Thus the
result map does not consider propagated attributes as parameters itself.
}


\vspace{0.5mm}
\tinysection{Query Transformations}
We present a set of query transformations, through examples for brevity, that
can be used by our algorithm to simplify and optimize queries.
\comment{
The first is a canonicalization of queries into a \textit{recursively
polynomial} form. A polynomial query is a query represented as a sum of
\textit{monomials}, where monomials are products of any other type of query
(constraints, aggregates, etc. but not sums or products). This is a polynomial
with two monomials:
\begin{align*}
\calcsum( & R(\v{A,B}) * S(\v{C,D}) * \calcgt(\v{B}-\v{C}) *
\calceq(\v{A}-\v{D})) * \\
& \calcsum(T(\v{E,F}) * \v{E}) + -\calcsum(U(\v{G,H}) * \calceq(\v{H}-5))
\end{align*}
The following query is not a polynomial:

$\calcsum(R(\v{A,B}) + (S(\v{C,D}) * \v{C})) *
 \calcsum(T(\v{E,F}) * \calceq(\v{E}-10))$

\noindent because of the addition inside the first sum aggregate. Due to nested
queries, we define our normal form recursively, where each nested
query is also in polynomial form. We require this normal form to easily apply
the following simplifications.
}

To simplify queries, we apply unification, which facilitates variable
elimination, and then factorization, which separates a complex monomial into a
product of simpler monomials. First we give an example of unification and
variable elimination: \todo{xxx}

Now, we demonstrate factorization: \todo{xxx}

Above, \todo{description}

Finally, we present a transformation related to binding propagation, called
preaggregation. This ensures that our product operation propagates the minimal
number of variables, when considering a left-associative multiplication.
The VWAP query [REF in this section] would result in the following after
preaggregation:

\vspace{-3mm}
\begin{align*}
\calcsum(
& \calcsum(\tuple{\v{P0}}, B(\v{P0,V0}) * \v{P0} * \v{V0}) *\\
& \calcgt(0.25 * \calcsum(B(\v{P1,V1}) * \v{V1}) \\
& \qquad \; \; - \calcsum(B(\v{P2,V2}) * \v{V2} * \calcgt(\v{P2-P0})))
\end{align*}

\noindent In contrast to the original VWAP query, the subexpression
$B(\v{P0,V0}) * \v{P0} * \v{V0}$ is preaggregated by an enclosing sum aggregate
to only propagate $\v{P0}$ to the nested query, and not $\v{P0,V0}$.

\tinysection{Incremental Processing}
So far, we have described queries, with no mention of incremental processing. We
now describe a transformation to compute the \textit{delta} of a query, which
computes the increment for a query given an update to one of its input
relations. The \textit{delta is itself a query}, and conceptually
is derived by replacing the input relation being updated with a set of
parameters. These parameters are passed to the transition program, thus the
delta query can be thought of as a parameterized SQL query. Our transformation
rules for computing delta queries are:

\vspace{-3mm}
\begin{align*}
\comment{
\Delta_{+R(\vec{x} \mapsto \vec{t})} c := & \; 0
\\
\Delta_{+R(\vec{x} \mapsto \vec{t})} Var(y) := & \; 0
\\
}
\Delta_{+R(\vec{x} \mapsto \vec{t})} R(\vec{x}) := & \;
\prod_i^{sch(\vec{x})} x_i := t_i
\\
\comment{
\Delta_{+R(\vec{x} \mapsto \vec{t})} S(\vec{y}) := & \; 0
\\
}
\Delta_{+R(\vec{x} \mapsto \vec{t})}
\calcsum(\vec{x},\q) := & \; \calcsum(\vec{x},\Delta\q)
\\
\Delta_{+R(\vec{x} \mapsto \vec{t})} (\qa + \qb) := & \;
(\Delta\qa + \Delta\qb)
\\
\Delta_{+R(\vec{x} \mapsto \vec{t})} (\qa * \qb) := & \;
(\Delta \qa * \qb) +
(\qa * \Delta \qb) +
(\Delta \qa * \Delta \qb)
\\
\Delta_{+R(\vec{x} \mapsto \vec{t})} \theta(\q) := & \;
(\theta(\q + \Delta \q) * \overline{\theta}(\q)) -
(\overline{\theta}(\q+\Delta \q) * \theta(\q))
\\
\Delta_{+R(\vec{x} \mapsto \vec{t})} -\q := & \;
    -(\Delta \q)
\\
\Delta_{+R(\vec{x} \mapsto \vec{t})} (x := \q) := & \;
    (x := \Delta \q)
\end{align*}

The above top-down rules specify deltas for complex terms. In addition, deltas
of constants and variables yield 0, and the delta of a relation other than the
one being updated also yields 0 (i.e. the rule: $\Delta_{+R(\vec{x} \mapsto
\vec{t})} S(\vec{y}) := \; 0$). Also note, we have no rule for maps, since maps
do not appear in user queries. All of these transformations are applied before
our algorithm introduces maps. These rules are similar to those from
incremental view maintenance, with the exception of our rule for constraints,
which can handle nested queries. To the best of our knowledge, we have not seen
this addressed before. We wrap up deltas with two insights: i) delta queries are
nearly always \textit{simpler} than their parent queries, with the exception of
nested queries; ii) queries are closed under taking deltas, that is our delta
queries are in the same language fragment, they too are SQL queries.
We will need to build a main-memory SQL engine, and we talk about novel
approaches with code generation in our algorithm.

\tinysection{Compiling Transition Programs}
We can now piece together the various transformations above, to perform
\textit{recursive query compilation}. Our algorithm produces transition
programs, which have the following grammar:

\vspace{-3mm}
\begin{align*}
M3    & \; \mbox{::= on (insert$|$delete$|$update) }
           R(\vec{x}\vec{y}) \; \{ stmt^* \}\\
\comment{event & \; \mbox{::= insert $|$ delete}\\}
stmt  & \; \mbox{::= } m[\vec{x}\vec{i}][\vec{y}\vec{j}] \;
                       \mbox{{\tt $\pm$=}} \; \q\\
\end{align*}

\noindent Transition programs as simple sequences of map updates.
Here $\q$ refers to our query representation, resulting from the fact that
queries are closed under deltas. Above, the function has arguments
$\vec{x}\vec{y}$, referring to the transition parameters which will be used in
both the LHS map of the statement as can be seen, as well as in the RHS delta
query.
The transition program for VWAP is:

\begin{verbatim}
on_insert_bids(p, v) {
  // aliases due to limited presentation space.
  // these are inlined in our code.
  c1 = 4*q2[p][] - q1[][];
  c2 = 4*q2[p][] - q1[][]+v;
  c3(d) = fun d -> 4*q2[d][] - q1[][];
  c4(d) = fun d -> 4*(q2[d][]+(v*<(d-p)))-q1[][]+v);

  // q1     = sum v from bids
  // q2(p2) = sum v from bids where p > p2
  // q3     = sum p*v from bids group by p
  // q4     = sum v from bids group by p
  q[][]   += p * v * >(c1);  
  q[][]   += sum(d, q3[][d] * <=(c3(d)) * >(c4(d));
  q[][]   -= sum(d, q3[][d] * >(c3(d)) * <=(c4(d));
  q[][]   += p * v * <=(c1) * >(c2);
  q[][]   -= p * v * >(c1) * <=(c2);
  q1[][]  += v; q2[d][] += v * >(p-d); 
  q3[][p] += p * v; q4[][p] += v;
}
\end{verbatim}

In our implementation, the RHS queries in these statements are compiled down to
C code (omitted for space).
\todo{Talk about higher-order deltas here.}
One issue that arises is on the arrival of new parameter values which we have
not seen previously, for both map lookups (map accesses in the RHS queries) and
map updates (map accesses on the LHS of statements). This requires
\textit{initial value computation}, which for queries with only simple equality
constraints has value 0, but in general requires evaluation of a parent query
instead of its delta. The above program omits initializers.

\def \alg         {{\bf algorithm}}
\def \algbegin    {{\bf begin}}
\def \algend      {{\bf end}}
\def \algforeach  {{\bf for each}}
\def \algdo       {{\bf do}}
\def \algdone     {{\bf done}}
\def \algreturn   {{\bf return}}
\def \algcomment#1{{\tt //} #1}

\def \codeforeach {{\tt for}}
\def \codev#1     {\mbox{{\tt #1}}}

A simplified algorithm for producing the above is:

\vspace{-1mm}
\begin{tabbing}
\alg\ Compile(\q: query, m: map name, $\vec{x}$: map keys) \\
\algcomment{returns triggers (a set of map update statements)}\\
\algcomment{for update events to relations in \q} \\
$\Gamma_{\q} := \Gamma$\\
\algforeach\ base relation $R$ in \q,
               $\pm$ in $\{\v{insert},\v{delete}\}$
\algdo \\
~~\= $\vec{t}$ := fresh variables for columns of $R$
     \algcomment{trigger args}\\
  \> $\vec{b} \; := \; \vec{t} \; \cup \; \vec{x}$
     $\qquad \qquad \qquad \qquad \qquad$ \algcomment{bound vars}\\
  \> $\v{\q}_{init}$ := MakeInitializer(\q)\\
  \> \algforeach\ $\v{q}_{m_i}$ in Monomialize($\Delta\v{q}$) \algdo\\
\>~~\= ($\partial\v{q}_i$, $\Gamma_i$) :=\=\ ExtractSimplerQuery($\vec{b}$,\\
  \>\>\> ~~ SimplifyQuery($\partial\v{q}_{m_i}$, $\vec{b}$))\\
  \>\> $\partial_{init} := $ MakeInitializer($\partial\v{\q} _i$)\\
  \>\> $\v{s}_i$ := \= EliminateLoops(MakeStmt(\\
  \>\>\> ~~\{\codeforeach\ $\vec{x} \in \codev{m} [\vec{x}]:$
  $\codev{m} [\vec{x}]\tuple{\v{\q}_{init}} \pm = $
  $\partial\codev{q} _{i}\tuple{\partial_{init}}$\}))\\
  \>\> triggers[$R$] := triggers[$R$] $\cup$ \todo{Annotate($\v{s}_i$)}\\
  \>\> $\Gamma := \Gamma \bigcup_i \Gamma_i$
  \ \ \ \ \algcomment{eliminates duplicate maps}\\
  \>\algdone\\
\algdone\\
\algforeach\ $(q, m[\vec{x}]) \in \Gamma - \Gamma_{\q}$ \algdo\\
  \> triggers := triggers $\bigcup_{R}$ Compile($q, m, \vec{x}$); \\
\comment{\algdone\\}
\algreturn\ triggers
\end{tabbing}

\todo{
\begin{itemize}
  \item Simplify compilation algorithm
  \item Describe additional steps beyond sequentially applying transformations
    \begin{itemize}
    \item loop var simplification
    \item initializer expression computation
    \end{itemize}
\end{itemize}
}

\tinysection{Towards a Framework for Optimizing Physical Engine Properties}
Our implementation of delta queries appearing on the RHS of statements uses an
restricted functional programming language, where we can apply
techniques from structural recursion [REF], prior to generating low-level code. 
Structural recursion enables optimizations of arbitrarily nested structures such
as sets, bags and lists, and while it might not immediately be clear how this
pertains to delta queries on maps, we provide the following insight:
\textit{structural recursion enables programmatic representation and
manipulation of numerous physical-level properties, such as tuple
construction and pipelining}.

Our delta queries consist of many maps used as inputs to cross products and
joins based on the presence of binding propagation in multiplications. In a
traditional DBMS engine treats, cross products and join operators work on
relations, to produce relations, ``flattening'' intermediate results into rows.
Column-stores have argued for the late materialization of tuples [REF: Abadi
ICDE 2007]. We produce intermediate results in a general nested form (think of
nested relations) which may include multiple levels of nesting after combining
several maps. Then, we can exploit structural recursion which critically makes
use of function composition and inlining, to programmatically control where, and
how much tuple construction we perform.

We show a structural recursion example for another physical-level transformation
on the following query: \todo{3-way join as binary join-tree w/ maps.}

We can transform this to: \todo{3 way join as 3 level nested loops w/ no
intermediates.} \todo{Describe benefits.}

To summarize, to the best of our knowledge, DBToaster incorporates the first
query representation (in functional form) for programmatic manipulation of
physical aspects of plans and operators. We can do this because we are reasoning
about query evaluation from a data structure perspective, not an operator
abstraction (which encapsulates and hides data structures). The techniques we
are developing will be relevant to general main-memory query processing beyond
dynamic data, since our delta queries are the same as standard SQL queries.
}