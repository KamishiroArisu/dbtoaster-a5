\documentclass[10pt,twocolumn]{article}

\usepackage{latexsym}
\usepackage{amsmath}
%\usepackage{epsfig}
%\usepackage{epic}
%\usepackage{eepic}
%\usepackage{xspace}
\usepackage{pst-tree}


%\addtolength{\textwidth}{1in}
%\addtolength{\oddsidemargin}{-0.5in}
%\addtolength{\evensidemargin}{-0.5in}
%\addtolength{\textheight}{0.8in}
%\addtolength{\topmargin}{-0.5in}
%\leftmargini 2.9ex



\def\punto{$\hspace*{\fill}\Box$}
\newcommand{\nop}[1]{}
\newcommand{\tuple}[1]{{\langle#1\rangle}}
\def\lBrack{\lbrack\!\lbrack}
\def\rBrack{\rbrack\!\rbrack}
\newcommand{\Bracks}[1]{\lBrack#1\rBrack}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{metatheorem}{Metatheorem}[section]
\newtheorem{example}[theorem]{Example}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{proviso}[theorem]{Proviso}
\newtheorem{todo}[theorem]{ToDo}


\title{DBToaster: Compiling main-memory database query processors\thanks{Or a better title.}}
%\author{Yanif Ahmad and Christoph Koch and Oliver if he stops being a slacker}
\date{}


\begin{document}


\maketitle


\begin{abstract}
The goal of this paper is world domination.
\end{abstract}


\section{Introduction}


We compile queries into C programs. Queries are incrementally maintained.
We are smart about creating data structures for very efficiently keeping query
results up to date. The programming interface supports update triggers as
well as cursor-based iteration over the current query result.

Tasks:
\begin{itemize}
\item
Compile multiple queries into common code, share data structures.

\item
How to compile queries of which some selection conditions can be modified at
runtime? (As in ODBC prepare statements.)

\item
Scale up using data partitioning, parallelization. This is not the focus of
this paper.

\item
Should we say something about accessing secondary storage, or will we leave
this out of scope? If we are not restricted to streaming scenarios, we may
have broader applicability of our techniques.

\item
We have to analyse our main memory consumption.
\end{itemize}


Aim: query processing where the queries are fixed at compile time.
In particular applications where there is no large static database of which
only a small part needs to be processed. The approach works particularly
well if the data arrives on a stream or changes very rapidly

We assume that there is only a single user who performs updates, and that
we do not care about concurrency control.
This is not an OLTP scenario.

Applications:
\begin{itemize}
\item
Processing order books. Give a nice example of a trading strategy that
delegates the bulk of the work to compiled SQL queries.
This is a nice scenario because order books do not get very large (if we
want to process several order books, we can nicely partition the work by
order book across several machines), change extremely rapidly, and the
success of trading depends crucially on the speed with which the programmed
strategies process the data.

\item
Data warehouse loading: data integration and aggregation.
Commercial data warehouse loaders also use straight-line code for aggregation,
but the data integration queries that are executed before aggregation are currently not compiled. Compiling them only yields a really substantial improvement
if the integration and aggregation queries are compiled together. This may substantially reduce the time taken to load a warehouse. (Here we may have to scale up by using several machines.)
\end{itemize}

Claims / theses regarding query processing in main-memory databases (to be verified by experiments):
\begin{enumerate}
\item
When we compile queries to straight-line C code, it is best to use incremental
maintenance techniques to eagerly keep query results up to date.

\item
Index nested loop joins on main memory hash tables
dominate all other join techniques in the compiled
main-memory database setting.
It is worth having hash tables whose buckets are sorted, though (e.g. for
top-k query processing).

\item
There is something to be gained from bulk updates.
do we not just want to support bulk updates of one kind (e.g., just inserts),
but mixtures of inserts, updates, and deletes? Is this an optimization, and
worth the work?

\item
There is no point in adaptivity beyond bulk updates.
\end{enumerate}


Experiments:
Destroy classical databases (4 orders of magnitude improvement). Demonstrate
that incremental maintenance is a good idea for aggregates (two orders
of magnitude improvement over compiled non-incremental code).


\section{Query Compilation}


\def\algsum{\mathrm{sum}}
\def\algagg{\mathrm{agg}}


\begin{figure*}
\begin{eqnarray}
\rho_{\vec{A}\vec{B}}(R) \bowtie \rho_{\vec{A}\vec{C}}(\{ \tuple{\vec{a}\vec{c}} \})
&\vdash&
\sigma_{\vec{A}=\vec{a}}(\rho_{\vec{A}\vec{B}}(R)) \times \rho_{\vec{C}}(\{ \vec{c} \})
\label{r1}
\\
\pi_{\vec{A}}(\rho_{\vec{A}}(R) \times \rho_{\vec{B}}(\{ \vec{b} \}))
&\vdash&
\rho_{\vec{A}}(R)
\label{r2}
\\
\rho_{A}(\{\vec{a}\}) \times \rho_{\vec{B}}(R)
&\vdash&
\sigma_{A=a}(\rho_{A}(\{\vec{a}\}) \times \rho_{\vec{B}}(R))
\label{r3}
\\
\algagg_{f(A,\vec{B})}(\sigma_{A=a}(R))
&\vdash&
\algagg_{f(a,\vec{B})}(\sigma_{A=a}(R))
\label{r4}
\\
\algsum_{f(\vec{A}) * g(\vec{B})}(\rho_{\vec{A}}(R) \times \rho_{\vec{B}}(S))
&\vdash&
\algsum_{f(\vec{A})}(\rho_{\vec{A}}(R)) *
\algsum_{f(\vec{B})}(\rho_{\vec{B}}(S))
\label{r5}
\\
\algsum_{a * f(\cdot)}(R)
&\vdash&
a * \algsum_{f(\cdot)}(R)
\label{r6}
\\
\algsum_{f(\cdot) + g(\cdot)}(R)
&\vdash&
\algsum_{f(\cdot)}(R) + \algsum_{g(\cdot)}(R)
\label{r7}
\\
\max_{a + f(\cdot)}(R)
&\vdash&
a + \max_{f(\cdot)}(R)
\label{r8}
\\
\max_{f(\vec{A}) + g(\vec{B})}(\rho_{\vec{A}}(R) \times \rho_{\vec{B}}(S))
&\vdash&
\max_{f(\vec{A})}(\rho_{\vec{A}}(R)) +
\max_{f(\vec{B})}(\rho_{\vec{B}}(S))
\label{r9}
\\
\max_{a * f(\vec{B})}(\rho_{\vec{B}}(R))
&\vdash&
\left\{
\begin{array}{lll}
a * \min_{f(\vec{B})}(\rho_{\vec{B}}(R)) & \dots & a < 0 \\
0                                        & \dots & a = 0 \\
a * \max_{f(\vec{B})}(\rho_{\vec{B}}(R)) & \dots & a > 0
\end{array}
\right.
\label{r10}
\\
\max_{f(\vec{A}) * g(\vec{B})}(\rho_{\vec{A}}(R) \times \rho_{\vec{B}}(S))
&\vdash&
\max\Big\{
\max_{f(\vec{A})}(\sigma_{f(\vec{A}) \ge 0}(\rho_{\vec{A}}(R))) *
\max_{g(\vec{B})}(\rho_{\vec{B}}(S)),
\nonumber\\
&& \quad\quad\;\;\,
\max_{f(\vec{A})}(\underbrace{\sigma_{f(\vec{A}) < 0}}_{\mathrm{optional}}(\rho_{\vec{A}}(R))) *
\max_{g(\vec{B})}(\sigma_{f(\vec{B}) \ge 0}(\rho_{\vec{B}}(S))),
\nonumber\\
&& \quad\quad\;\;\,
\min_{f(\vec{A})}(\sigma_{f(\vec{A}) < 0}(\rho_{\vec{A}}(R))) *
\min_{g(\vec{B})}(\sigma_{f(\vec{B}) < 0}(\rho_{\vec{B}}(S)))
\Big\}
\label{r11}
\\
\max_a(R)
&\vdash&
\left\{
\begin{array}{lll}
a       & \dots & \algsum_1(R) > 0 \\
-\infty & \dots & \algsum_1(R) = 0 \\
\end{array}
\right.
\label{r12}
\end{eqnarray}

In particular, if $g(\cdot) = 1$, then Rule~(2) gives
\[
\algsum_{f(\vec{A})}(\rho_{\vec{A}}(R)) *
\algsum_{1}(\rho_{\vec{B}}(S))
=
\algsum_{f(\vec{A})}(\rho_{\vec{A}}(R)) * |S|.
\]

\caption{Rewrite rules. agg can be either sum, max, or min.
count is sum$_1$.}
\label{fig:rules}
\end{figure*}



In this section, an expression of the form
\[
\algagg_f(\sigma_{\vec{A}=\vec{a}}(Q))[\vec{a}]
\]
is a map for an aggregate-group by query
\[
\mbox{select $\vec{A}$, agg($f$)
from $Q$
group by $\vec{A}$}.
\]
Given a group $\vec{a}$, the map returns
the aggregate value
$\algagg_f(\sigma_{\vec{A}=\vec{a}}(Q))$ for it.
An aggregate $\algagg$ (either sum, max, or min) returns exactly
one value -- the aggregate value.

The main rewrite step is the following.
We exploit the fact that for our aggregate functions $\algagg$,
\begin{multline*}
\algagg_f(\sigma_{\vec{A}=\vec{a}}(Q \cup \Delta Q))[\vec{a}]
= \\
\algagg(\algagg_f(\sigma_{\vec{A}=\vec{a}}(Q))[\vec{a}],
\algagg_f(\sigma_{\vec{A}=\vec{a}}(\Delta Q))[\vec{a}]).
\end{multline*}


Consider an aggregate-group by query
\[
\algagg_{f(\vec{a}, \vec{B}, \vec{C}, \vec{D})}
(\sigma_{\vec{A}=\vec{a}}(R_1 \bowtie \dots \bowtie R_k))[\vec{a}]
\]
where the schema of $R_1 \bowtie \dots \bowtie R_{k-1}$ is
$\vec{A}\vec{B}\vec{C}$ and the schema of
$R_k$ is $\vec{C}\vec{D}$.

W.l.o.g., we consider the case of an insertion of tuple
$\tuple{\vec{c},\vec{d}}$ into relation $R_k$.

We rewrite
$
\algagg_f(\sigma_{\vec{A}=\vec{a}}(\Delta Q))[\vec{a}]
$, that is,
\[
\algagg_{f(\vec{a}, \vec{B}, \vec{C}, \vec{D})}
(\sigma_{\vec{A}=\vec{a}}(R_1 \bowtie \dots \bowtie R_{k-1} \bowtie \{\tuple{\vec{c}\vec{d}}\}))[\vec{a}]
\]
to
\begin{equation}
\algagg_{f(\vec{a}, \vec{B}, \vec{c}, \vec{d})}
(\sigma_{\vec{A}\vec{C}=\vec{a}\vec{c}}(R_1 \bowtie \dots \bowtie R_{k-1}))[\vec{a}\vec{c}\vec{d}].
\label{eq:1}
\end{equation}

Figure~\ref{fig:rules} provides a set of rewrite rules, of which rules
\ref{r1}, \ref{r2}, \ref{r3}, and \ref{r4} are sufficient to  perform this
rewriting.

Since we would like the maps that have to be maintained to be as simple as
possible, we will try to express Equation~\ref{eq:1} in terms of 
aggregates
\begin{equation}
\algagg_{f'(\vec{a}, \vec{B}, \vec{c})}
(\sigma_{\vec{A}\vec{C}=\vec{a}\vec{c}}(R_1 \bowtie \dots \bowtie R_{k-1}))[\vec{a}\vec{c}]
\label{eq:2}
\end{equation}
which do not use $\vec{d}$.

In most cases
this is possible using the rewrite rules of Figure~\ref{fig:rules}.
Assuming that $f$ is an arithmetic expression built using addition and multiplication (and constants which may be negative), we can turn $f$ into an equivalent
expression that is a sum of products (by exploiting distributivity).

Let the aggregate be sum. In that case the rewriting of Equation~\ref{eq:1}
so as to eliminate the constants $\vec{d}$
is always possible using the rules \ref{r6} and \ref{r7}.
In the case of max, the rewriting is usually possible. The simplest case
where it is not is $f = B_1 * d + B_2$.


\begin{proposition}
To do: Formalize this fact.
\end{proposition}


Note that our rewriting has removed relation $R_k$ from the query to be
incrementally maintained. Inductively, we can solve the incremental maintenance
problem by just maintaining the maps constructed using this rewriting.


\begin{example}\em
Given schema $R(A,B)$, $S(B,C)$, $T(C,D)$.
We incrementally maintain the aggregate query
\[
s := \algsum_{A*D}(R \bowtie S \bowtie T).
\]
\begin{itemize}
\item
Insert R(a,b):
\begin{eqnarray*}
\Delta s &=& \algsum_{A*D}(\{\tuple{a,b}\} \bowtie S \bowtie T)
\\ &\stackrel{\ref{r1}}{=}&
\algsum_{A*D}(\{a\} \times \sigma_{B=b}(S) \bowtie T)
\\ &\stackrel{\ref{r3},\ref{r4}}{=}&
\algsum_{a*D}(\sigma_{B=b}(S) \bowtie T)
\\ &\stackrel{\ref{r6}}{=}&
a * \underbrace{\algsum_{D}(\sigma_{B=b}(S) \bowtie T)}_{s_D[b]}
\end{eqnarray*}

\item
Insert S(b,c):
\begin{eqnarray*}
\Delta s &=& \algsum_{A*D}(R \bowtie \{\tuple{b,c}\} \bowtie T)
\\ &\stackrel{\ref{r1}*}{=}&
\algsum_{A*D}(\sigma_{B=b}(R) \times \sigma_{C=c}(T))
\\ &\stackrel{\ref{r5}}{=}&
\underbrace{\algsum_{A}(\sigma_{B=b}(R))}_{s_A[b]} *
\underbrace{\algsum_{D}(\sigma_{C=c}(T))}_{s_D[c]}
\end{eqnarray*}

\item
Insert T(c,d): (analogous to insertion of R(a,b))
\begin{eqnarray*}
\Delta s &=& \algsum_{A*D}(R \bowtie S \bowtie \{\tuple{c,d}\})
\\ &=&
\underbrace{\algsum_{A}(R \bowtie \sigma_{C=c}(S))}_{s_A[c]} * d
\end{eqnarray*}
\end{itemize}

We incrementally maintain $s_D[b]$, $s_A[b]$, $s_D[c]$, and
$s_A[c]$ as well.

\begin{itemize}
\item
Insert R(a,b):
\begin{eqnarray*}
\Delta s_A[b] &=& \algsum_{A}(\{\tuple{a,b}\}) = a
\\
\mbox{foreach $c$: }
\Delta s_A[c] &=& \algsum_{A}(\{\tuple{a,b}\} \bowtie \sigma_{C=c}(S))
\\ &\stackrel{\ref{r1},\ref{r3},\ref{r4},\pi}{=}&
\algsum_{a}(\sigma_{BC=bc}(S))
\\ &\stackrel{\ref{r6}}{=}&
a * \underbrace{\algsum_{1}(\sigma_{BC=bc}(S))}_{s_1[b,c]}
\end{eqnarray*}

(Analogously insert T(c,d).)

\item
Insert S(b,c):
\begin{eqnarray*}
\Delta s_A[c] &=&
\algsum_{A}(R \bowtie \{\tuple{b,c}\})
\\ &\stackrel{\ref{r1}}{=}&
\algsum_{A}(\sigma_{B=b}(R) \times \{c\})
\\ &\stackrel{\pi}{=}&
\algsum_{A}(\sigma_{B=b}(R))
\;=:\; s_A[b]
\\
\Delta s_D[b] &=&
\algsum_{D}(\{\tuple{b,c}\} \bowtie T)
\\ &=&
\algsum_{D}(\{b\} \times \sigma_{C=c}(T))
\\ &=&
\algsum_{D}(\sigma_{C=c}(T))
\;=:\; s_D[c]
\end{eqnarray*}
\end{itemize}

Finally, we want to incrementally maintain $s_1[b,c]$:
\begin{itemize}
\item
Insert S(b,c):
\[
\Delta s_1[b,c] =
\algsum_{1}(\{\tuple{b,c}\}) = 1
\]
\end{itemize}

Thus the code is:
\begin{verbatim}
on insert into R values (a,b)
{
   s += a * s_D[b];
   s_A[b] += a;
   foreach c (in Cs[b]) do
      s_A[c] += a * s_1[b,c];
}

on insert into R values (b,c)
{
   s += s_A[b] * s_D[c];
   s_A[c] += s_A[b];
   s_D[b] += s_D[c];
   s_1[b,c] += 1;
}

on insert into T values (c,d)
{
   s += s_A[c] * d;
   s_D[c] += d;
   foreach b (in Bs[c]) do
      s_D[b] += s_1[b,c] * d;
}
\end{verbatim}
\punto
\end{example}


\begin{example}\em
Consider the same query as above where sum is replaced by max,
\[
m := \max_{A*D}(R \bowtie S \bowtie T).
\]

On insert into R values $(a,b)$: $m := \max(m, m')$ where
\begin{eqnarray*}
m' &=&
\max_{A*D}(\{\tuple{a,b}\} \bowtie S \bowtie T)
\\
&\stackrel{\ref{r1},\ref{r3},\ref{r4}}{=}&
\max_{a*D}(\sigma_{B=b}(S) \bowtie T)
\\
&\stackrel{\ref{r10}}{=}&
\left\{
\begin{array}{lll}
a * \min_{D}(\sigma_{B=b}(S) \bowtie T) & \dots & a < 0 \\
a * \max_{D}(\sigma_{B=b}(S) \bowtie T) & \dots & a \ge 0
\end{array}
\right.
\end{eqnarray*}

For the incremental maintenance of $S$ and $T$, we have to maintain
$\min_A[b] = \min_A(\sigma_{B=b}(R))$,
$\max_A[b] = \max_A(\sigma_{B=b}(R))$,
$\min_A[c] = \min_A(R \bowtie \sigma_{C=c}(S))$ and
$\max_A[c] = \max_A(R \bowtie \sigma_{C=c}(S))$.
For instance,
$\max_A[c] := \max(\max_A[c], \max_A'[c])$
where
\begin{eqnarray*}
\max_A[c] &=&
\max(\max_A[c], \max_A(\{\tuple{a,b}\} \bowtie \sigma_{C=c}(S)))
\\
&\stackrel{\ref{r1},\ref{r3},\ref{r4}}{=}&
\max(\max_A[c], \max_a(\sigma_{BC=bc}(S)))
\\
&\stackrel{\ref{r12}}{=}&
\left\{
\begin{array}{lll}
\max(\max_A[c], a) & \dots & s_1[b,c] > 0 \\
\max_A[c]          & \dots & s_1[b,c] = 0
\end{array}
\right.
\end{eqnarray*}
where we incrementally maintain
$s_1[b,c] = \algsum_1(\sigma_{BC=bc}(S))$.

Thus the code for maintaining the datastructures on an insert of $R(a,b)$ is
\begin{verbatim}
m = max(m, ((a<0) ? min_D[b] : max_D[b]));
max_A[b] = max(max_A[b], a);
min_A[b] = min(min_A[b], a);
if (s_1[b,c] > 0)
{
   max_A[c] =  max(max_A[c], a);
   min_A[c] =  min(min_A[c], a);
}
\end{verbatim}
\punto
\end{example}


\section{Structural Query Decomposition}


The examples of the previous section have demonstrated how the rewrite
rules of Figure~\ref{fig:rules} can be used to decompose a complex
aggregate into smaller parts. For example,
we were able to decompose
\[
\Delta s = \algsum_{A*D}(R \bowtie S \bowtie T)
\]
on the insertion of $S(b,c)$ into
\[
\algsum_{A}(\sigma_{B=b}(R)) * \algsum_D(\sigma_{C=c}(T)).
\]

This decomposition was easy to find because the query was
very simple. For complex queries, we need some way of understanding the
join structure of the query to find good decomposition. The natural tool
for this are hypertree decompositions.


\begin{example}\em
The schema is
$R_1\{A,B,C\}$, $R_2\{B,D,E\}$, $R_3\{C,F,G\}$, $R_4\{F,H\}$,  $R_5\{G,I,J\}$,
and $R_6\{I,J,K,L\}$ and
the query is
\[
s := \algsum_{A*L}(\sigma_{HK=hk}(R_1 \bowtie \dots \bowtie R_6))[h,k].
\]
This query maliciously asks for tuples to be grouped by columns $H$ and $K$,
which are quite distant in the query's hypergraph. 

Let us insert tuple $R_1(a,b,c)$.
This is an acyclic query. This is a hypertree decomposition with $R_1$ as
the root node:
\[
\psset{levelsep=12mm}
\pstree{\TR{\framebox{$R_1\{A,B,C\}$}}}
{
   \TR{\framebox{$R_2\{B,D,E\}$}}^B
   \pstree{\TR{\framebox{$R_3\{C,F,G\}$}}_{C; [H,K]}}
   {
      \TR{\framebox{$R_4\{F,H\}$}}^{F; [H]}
      \pstree{\TR{\framebox{$R_5\{G,I,J\}$}}_{G; [K]}}
      {
         \TR{\framebox{$R_6\{I,J,K,L\}$}}_{I,J; [K]}
      }
   }
}
\]

The edges are annotated with the columns that have to be passed between the nodes.
Now
\begin{eqnarray*}
\Delta s &=&
\algsum_{A*L}(\sigma_{HK=hk}(\{a,b,c\} \bowtie R_2 \bowtie \dots \bowtie R_6))[\cdot]
\\
&=&
a * \algsum_{L}(\sigma_{BCHK=bchk}(R_2 \bowtie \dots \bowtie R_6))[\cdot]
\\
&=&
a * \algsum_{L}(\sigma_{B=b}(R_2) \times \sigma_{CHK=chk}(R_3 \bowtie \dots \bowtie R_6))[\cdot]
\\
&=&
a * 
\algsum_1(\sigma_{B=b}(R_2))[b] \\
&*& 
\algsum_L(\sigma_{CHK=chk}(R_3 \bowtie R_4 \bowtie R_5 \bowtie R_6))[c,h,k].
\end{eqnarray*}

If we want to insert into $R_3$, we reroot the hypertree decomposition
\[
\psset{levelsep=12mm}
\pstree{\TR{\framebox{$R_3\{C,F,G\}$}}}
{
   \pstree{\TR{\framebox{$R_1\{A,B,C\}$}}^C}
   {
      \TR{\framebox{$R_2\{B,D,E\}$}}^B
   }
   \TR{\framebox{$R_4\{F,H\}$}}^{F; [H]}
   \pstree{\TR{\framebox{$R_5\{G,I,J\}$}}_{G; [K]}}
   {
      \TR{\framebox{$R_6\{I,J,K,L\}$}}_{I,J; [K]}
   }
}
\]
and rewrite as follows:
\begin{eqnarray*}
\Delta s &=&
\algsum_{A*L}(\sigma_{HK=hk}(R_1 \bowtie R_2 \bowtie \{c,f,g\}
\\
&& \quad \bowtie R_4 \bowtie R_5 \bowtie R_6))[\cdot]
\\
&=&
\algsum_{A*L}(\sigma_{C=c}(R_1 \bowtie R_2) \times \sigma_{FH=fh}(R_4)
\\
&& \quad
\times \sigma_{GK=gk}(R_5 \bowtie R_6))[\cdot]
\\
&=&
\algsum_{A}(\sigma_{C=c}(R_1 \bowtie R_2))[c]
\\
&*& \algsum_{1}(\sigma_{FH=fh}(R_4))[fh]
\\
&*& \algsum_L(\sigma_{GK=gk}(R_5 \bowtie R_6))[gk]
\end{eqnarray*}
\punto
\end{example}


\begin{example}\em
If the query is acyclic, nothing really changes.
Consider the previous query where the schema of $R_5$ is now
$\{E,G,I,J\}$ (thus the query becomes cyclic).

The following is a hypertree decomposition rooted at $R_3$:
\[
\psset{levelsep=12mm}
\pstree{\TR{\framebox{$R_3\{C,F,G\}$}}}
{
   \TR{\framebox{$R_4\{F,H\}$}}^{F; [H]}
   \pstree{\TR{\framebox{$R_1\{A,B,C\}, R_5\{E,G,I,J\}$}}_{C,G; [K]}}
   {
      \TR{\framebox{$R_2\{B,D,E\}$}}^{B,E}
      \TR{\framebox{$R_6\{I,J,K,L\}$}}_{I,J; [K]}
   }
}
\]
Thus $\Delta s$ for the insertion of $R_3(c,f,g)$ is
\begin{eqnarray*}
\Delta s &=&
\algsum_{A*L}(\sigma_{HK=hk}(R_1 \bowtie R_2 \bowtie \{c,f,g\}
\\
&& \quad \bowtie R_4 \bowtie R_5 \bowtie R_6))[\cdot]
\\
&=&
\algsum_{1}(\sigma_{FH=fh}(R_4))[fh]
\\
&*& 
\underbrace{\algsum_{A*L}(\sigma_{CGK=cgk}(R_1 \bowtie R_2 \bowtie R_5 \bowtie R_6))[cgk]}_{s_{A*L}[cgk]}
\end{eqnarray*}

On insertion of $R_5(e,g,i,j)$,
\begin{eqnarray*}
\Delta s_{A*L}[cgk]
&=&
\algsum_{A*L}(\sigma_{CGK=cgk}(R_1 \bowtie R_2 \\
&& \quad \bowtie \{\tuple{e,g,i,j}\} \bowtie R_6))[\cdot]
\\
&=&
\algsum_{A*L}(\sigma_{C=c}(R_1) \bowtie \sigma_{E=e}(R_2) \\
&& \quad \times \sigma_{IJK=ijk}(R_6))[\cdot]
\\
&=&
\algsum_{A}(\sigma_{C=c}(R_1) \bowtie \sigma_{E=e}(R_2))[ce] \\
&& \quad * \algsum_L(\sigma_{IJK=ijk}(R_6))[ijk]
\end{eqnarray*}
\punto
\end{example}




\section{Future Work}


\begin{itemize}
\item
Programming language theory paper: how to compile SQL to use user-specified
data structures.

\item
Compiling down more general declarative languages, with operators and
aggregates whose semantics is definable in the framework. Applications e.g.\
probabilistic inference in graphical models. Compile the graph structure
of the graphical model and the inference algorithms (using e.g.\ mesage
passing techniques) into C code. The data to be processed are the factor
relations/conditional probability tables.

\item
Compiling database applications and the database server together into a single
program that runs robustly and requires no administration. I.e., combine
our query compilation work with automatic administration ideas, if any of
this is actually needed.
\end{itemize}



%\bibliographystyle{abbrv}
%\bibliography{bibtex}


\end{document}
