\section{Query Evaluation}

\begin{itemize}
  \item We now discuss our trigger evaluation language which is essentially a
  small fragment of OCaml, but can easily be translated to a pure imperative
  language. This language fragment is sufficient to implement the statement
  evaluation described here.
\end{itemize}

\subsection{Structural Recursion}

\def\ktclist{\mbox{List}}
\def\ktcmap{\mbox{Map}}
\def\apply{\mbox{apply}}
\def\seq{\mbox{seq}}
\def\ifelse{\mbox{ifelse}}
\def\mem{\mbox{mem}}
\def\lookup{\mbox{lookup}}
\def\slice{\mbox{slice}}
\def\setval{\mbox{set\_value}}
\def\setmap{\mbox{set\_map}}
\def\ktmap{\mbox{map}}
\def\ktflat{\mbox{flatten}}
\def\ktagg{\mbox{agg}}
\def\ktgb{\mbox{gb\_agg}}
\def\ktpwl{\mbox{pairwith}_1}
\def\ktpwr{\mbox{pairwith}_2}
\def\ktext{\mbox{ext}}
\def\ktid{\mbox{id}}

\begin{align*}
e \; \mbox{::-} & \; c \;|\; v \;|\; e + e \;|\; e * e \;|\; e \; \theta \; e
\;|\; e \neq 0?\; e : 0 \\
& |\; \mem(t,\vec{e}) \;|\; \lookup(t,\vec{e})\\
t \; \mbox{::-} & \; \ktclist(t) \;|\; \ktcmap(id,\vec{v_i},\vec{v_o})
  \; | \; \slice(t,\vec{e}) \;|\; \tuple{\vec{e}} \;|\; \pi_{\vec{i}}(t) \\
& |\; \lambda v . t \;|\; \Lambda v1,v2.t \;|\; \apply(t,t)
  |\; \seq(\vec{t}) \;|\; \ifelse(e,t,t) \\
& |\; \ktmap(t,t) \;|\; \ktflat(t) \;|\; \ktagg(t,e,t) \;|\; \ktgb(t,e,t,t)\\
& |\; \setval(id,\vec{e},\vec{e},t) \;|\; \setmap(id,\vec{e},t)
\end{align*}

\begin{itemize}
  \item Notational extensions for transformations, i.e. representations of
  composition and pairwith. Lets us write things in the same way as the Kleisli
  paper.
\end{itemize}

\begin{align*}
f \circ g & := \lambda x. \apply(f, \apply(g,x))
\\
f \times g & := \lambda xy. \tuple{apply(f, x), apply(g, y)}
\\
f \circ (g \times h) & := \lambda xy.
\apply(f, \tuple{\apply(g, x), \apply(h, y)})
\\
\ktext(f,x) & := \ktflat(\ktmap(f,x))
\\
\ktpwl(x,y) & := \lambda \tuple{x,y}. \ktmap(\lambda z.\tuple{z,y}, x)
\\
\ktpwr(x,y) & := \lambda \tuple{x,y}. \ktmap(\lambda z.\tuple{x,z}, y)
\end{align*}

\def \sr#1{\llbracket #1 \rrbracket_{SR}}

\tinysection{Map accesses}
\begin{itemize}
  \item Conditionals to test map key existence, potentially resulting in
  intial value computation.
  \item Updates to persistent collections for IVC.
  \item Map accesses yielding internal slice representation, i.e. collections.
  Statement RHS evaluation applies operations to whole collection, i.e.
  iteration/scans over the entire data structure rather than doing any
  complicated lookups/random accesses, suggesting a simple list-based
  implementation.
\end{itemize}

\begin{align*}
\sr{m[ & \vec{x}][\vec{y}] \tuple{init}} := \; \apply(\\
  & \lambda it. \ifelse(\mem(it, \vec{x}), \\
  & \quad \apply(\\
  & \quad \quad
    \lambda ot. \ifelse(\mem(ot, \vec{y}), \psi(ot, \vec{y}),\\
  & \quad \quad \quad
    \apply(\lambda iv. \seq(\phi(ot,\tuple{},\vec{y},iv), iv), \sr{init})), \\
  & \quad \quad \lookup(it, \vec{x})), \\
  & \quad \apply(\lambda iv.
       \seq(\phi(it,\vec{x},\vec{y},iv), iv), \sr{init})),\\
  & \ktcmap(m,\vec{x},\vec{y}))\\
\mbox{where} & \; \psi(m,\vec{x}) := 
                        \begin{cases}
                        \lookup(m,\vec{x}) & \mbox{if bound($\vec{x}$)}\\
                        \slice(m,\vec{x})  & \mbox{otherwise}
                        \end{cases}\\
\mbox{and}   & \; \phi(m,\vec{x},\vec{y},v) :=
                        \begin{cases}
                        \setval(m, \vec{x}, \vec{y}, v) & \mbox{if is\_val($v$)}
                        \\
                        \setmap(m, \vec{x}, v) & \mbox{otherwise}
                        \end{cases}
\end{align*}

\noindent\todo{Define bound(), is\_val() above}

\tinysection{Products, conditionals and bigsums}

\begin{align*}
\sr{e_1[\vec{w}][\vec{x}] \; & \theta \; e_2[\vec{y}][\vec{z}]} :=
  \ktflat(
\\
  \ktmap( & \lambda \vec{x}v_1.
  \ktmap(\lambda \vec{z}v_2. \tuple{\vec{x}\vec{z},\theta(v1,v2)},
         \sr{e_2[\vec{y}][\vec{z}]}),
\\
& \sr{e_1[\vec{w}][\vec{x}]}))
\\
\sr{e_1[\vec{x}][] \neq 0 \; ? \; & e_2[\vec{y}][\vec{z}] : 0} :=
\\
&
\begin{cases}
\sr{e_1[\vec{x}][]} \neq 0 \; ? \; \sr{e_2[\vec{y}][]} : 0
& \mbox{if $\vec{z} = \tuple{}$}
\\
e_2[\vec{y}][\vec{z}] * (e_1[\vec{x}][] \neq 0 \; ? \; 1 : 0)
& \mbox{otherwise}
\end{cases}
\end{align*}

\noindent\todo{Rewrite product in Kleisli form, i.e. with prod+prep phases}

\noindent\todo{Aggregation function semantics, i.e. what are x,y?}
\begin{align*}
\sr{ & m[\vec{x}][\vec{y}] \; \mbox{{\tt +}=} \sum_{\vec{z}}
    e[\vec{x}][\vec{y}\vec{z}]} :=
\\
& \begin{cases}
  \ktagg(\Lambda v_1,v_2. v_1+v_2 , 0,
         \sr{e[\vec{x}][\vec{y}\vec{z}]})
  & \mbox{if $\vec{y} = \tuple{}$}
  \\
  \ktgb(\Lambda v_1,v_2. v_1+v+2 , 0, \lambda \vec{y}\vec{z}.\vec{y},
        \sr{e[\vec{x}][\vec{y}\vec{z}]})
  & \mbox{otherwise}
  \end{cases}
\\
\sr{ & m[\vec{x}][\vec{y}] \; \mbox{:=} \sum_{\vec{z}}
    e[\vec{x}][\vec{y}\vec{z}]} :=
\\
& \begin{cases}
  \ktagg(\Lambda v_1,v_2. v_1+v_2 , 0, \sr{e[\vec{x}][\vec{y}\vec{z}]})
  & \mbox{if $\vec{y} = \tuple{}$}
  \\
  \ktgb(\Lambda v_1,v_2. v_1+v_2 , 0, \lambda \vec{y}\vec{z}.\vec{y},
        \sr{e[\vec{x}][\vec{y}\vec{z}]})
  & \mbox{otherwise}
  \end{cases}
\\
\end{align*}

\begin{itemize}
  \item Products as structural recursion composed map.
  \item LHS$\rightarrow$RHS projection+aggregation as structural recursion
  group-by aggregate.
  \item Bigsums as structural recursion aggregate.
\end{itemize}

\tinysection{External functions}
\begin{itemize}
  \item Several external functions required, which we cannot optimize in terms
  of structural recursion. However it turns out these all occur following
  statement RHS evaluation for maintaining the LHS map. These external
  functions are:
  \item Slice merging, i.e. combining delta and existing slice
  \item In var tier iteration. Allows us to avoid having side-effecting
  iteration as part of our language fragment, that is every expression in our
  language fragment yields a collection (which of course may be a singleton).
\end{itemize}

\tinysection{Structural recursion example}
\begin{itemize}
  \item Translation of VWAP M3 example to structural recursion.
  \begin{itemize}
    \item \todo{Awkward to write out map access code in full.}
    \item \todo{The goal should be to really represent the maps and aggregates
    applied to slice accesses for products etc in VWAP.}
  \end{itemize}
\end{itemize}

\def \srin#1{\llbracket #1 \rrbracket_{\mbox{\tiny{In}}}}
\def \srsub#1#2{(#1)[#2]}

\subsection{Program Optimization}
\begin{itemize}
  \item Product optimizations, define in monadic form, i.e. w/ type judgements
  in our grammar. 
  \begin{itemize}
    \item Define binary product/join in Kleisli syntax, and composition of
    binary joins, i.e. with maps as scans, and pairwith/prep composers,
    \item Show how this representation can capture any join tree, i.e.
    l/r-deep, bushy, etc.
    \item Discuss intermediates from composing, i.e. same as modern query plans.   
    \item Show transformation to a single n-way representation w/ no
    intermediates, listing inlining and substitution rules for Kleisli to our
    representation.
    \item Discuss need for optimizer, and how no current system optimizes both
    the arity of the join operator in addition to the composition plan. Our
    representation here lays the groundwork for this.
  \end{itemize}
  \item Aggregation pushdown, also w/ type judgements, using our grammar.
  \item Lookup lifting and combined delta+initial value optimization.
  \item Optimization examples.
  \item Category theory morphisms diagrams for optimizations.
\end{itemize}

\begin{align*}
\srin{\lambda \tuple{x,y}. & \apply(f \circ \ktpwl, \tuple{x,y})} :=
\\
    & \lambda \tuple{x,y}. \apply(f[2 \mapsto y], x)
\\
\srin{\lambda \tuple{x,y}. & \apply(f \circ \ktpwr, \tuple{x,y})} :=
\\
    & \lambda \tuple{x,y}. \apply(f[1 \mapsto x], y)
\\
\srin{\apply( & \lambda x.f, y)} := f[1 \mapsto y]
\\
\srin{\apply( & \lambda \tuple{x_1 \ldots x_n}.f, \tuple{y_1 \ldots y_n})} :=
\\
    & f[1 \mapsto y_1, \ldots, n \mapsto y_n]
\\
\srin{\apply(& f \circ g, y)} := \apply(f, g[1 \mapsto y])
\\
\srin{\apply(& f \circ g, \tuple{y_1,\ldots,y_n})} :=
\\
    & \apply(f, g[1 \mapsto y_1,\ldots,n \mapsto y_n])
\\
\srin{\lambda xy. \apply( & f \circ (\ktid \times h), xy)} :=
\\
    & \lambda xy. \apply(f, \tuple{x, \apply(h, y)})
\\
\end{align*}

\begin{align*}
\srsub{\lambda \tuple{x,y}. \apply(f, \tuple{x,y})}{1 \mapsto c} & :=
    \lambda y. \apply(f, \tuple{c,y})
\\
\srsub{\lambda x. \apply(f \circ g, x)}{1 \mapsto c} & :=
    \apply(f, g[1 \mapsto c])
\\
\srsub{\lambda c. \ktmap(\lambda \tuple{x,y}.
    \apply(f, \tuple{x,y}), c)}{1 \mapsto a} & :=
\\
    \lambda c. \ktmap( & \lambda y. \apply(f, \tuple{a,y}), c)
\end{align*}

\noindent\todo{Think about substitution more.
\begin{itemize}
  \item Substitution is not clean, requires lineage, i.e. subst of first
  argument is ambiguous for maps. We might want to subst both the map function,
  and the map function arg w.r.t tuples
\end{itemize}}

\noindent Aggregation transformation:

\begin{align*}
\ktagg(\Lambda_f, i) \circ \ktflat =
    \ktagg(\Lambda_f, i) \circ \ktmap(\ktagg(\Lambda_f, 0))
\end{align*}

\tinysection{Discussion}
\todo{Discussion of why such an approach can't be applied to standard
  relational plans? They can, query plan optimization has traditionally been
  applied to operators, whose design in turn has been focused on efficient
  out-of-core execution. Imperative and functional language compilers and
  optimizers have focused much more aggressively on a variety of optimization
  techniques for in-memory applications and our backend begins to touch on how
  to bridge this gap. e.g., how do we do schema/tuple-layout based register
  allocation}