
\begin{figure*}
\begin{center}
\includegraphics[width=\textwidth]{../graphs/graphs/bakeoff.pdf}
\caption{Cross-query comparison of our compiler in different depth-restricted modes, and the best performing streaming and database engine for each query.  Note the logscale on the y-axis.}
\label{fig:experiments:bakeoff}
\end{center}
\end{figure*}

We now analyze the performance of \dbtoaster.  As in Section \ref{sec:dbfail}, experiments are run on \todo{insert hardware configuration here}. 
 
Our analysis uses the queries from Examples \ref{ex:dbfail:stock}(PRICESPREAD),  \ref{ex:dbfail:tpch}(SHIPPING), and \ref{ex:dbfail:network}(SERVERLOAD), Queries numbers 3, 11, 17, 18, and 22 from the TPC-H\cite{tpch} benchmark, the VWAP query presented in \cite{kennedy-ahmad-koch-cidr:11}, and four additional financial queries: MISSEDTRADES, AXFINDER, BROKERSPREAD, and BROKERCOVARIANCE in the spirit of VWAP and PRICESPREAD.  These queries are presented in \todo{reference these queries somehow?}.

Queries were run on pre-generated traces until completion of the trace or a 1 hour cutoff.  Traces are implemented as follows: The financial queries: VWAP, MISSEDTRADES, AXFINDER, BROKERSPREAD, PRICESPREAD, and BROKERVARIANCE were run on a 2 million tuple trace of stock market activity for MSFT.  

The TPCH-H and SHIPPING queries were run on a database generated by dbgen\cite{tpch} with scaling factor 0.1 (100 MB).  Insertions are drawn from the data files for each table and interleaved in random order.  Note that this means that some insertions are performed before the foreign key that they reference, and that smaller datafiles finish earlier.  Although this is not expected behavior in a streaming setting, it serves to provide valuable insights about the difference between the performance characteristics of different types of insertions.

The SERVERLOAD query was run on a synthetically generated dataset using 1000 racks of 20 servers each, and 100,000 status updates each instantiated as a deletion followed by an insertion.

For comparison, we use a depth-limited instantiation of our compilation algorithm where maps are not materialized beyond a fixed number of recursive steps.  Compilation limited to depth 1 is approximately equivalent to traditional IVM techniques, while depth 0 is equivalent to re-evaluating the query on every insertion\footnote{We have implemented an in-memory query processing engine to support depth 1 and depth 0 compilation.  Although the capabilities of this engine are limited, we do not expect further optimizations  to have a meaningful impact on the processing times of our test queries.}.  We omit detailed Depth 0 performance measurements on graphs where these results are not visible due to scale, or where depth 0 and depth 1 performance are indistinguishable.  Memory measurements are taken using google-perftools\cite{perftools} and count only memory allocated to the persistent maps.

Note that \dbtoaster\ is able to take advantage of the TPC-H benchmark's append-only nature: The SHIPPING and the TPC-H queries are compiled without deletion triggers.  As a further optimization, all queries involving strings use a dictionary to compress string data before processing.

\subsection{Equijoins}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_tpch3.pdf}
\caption{Performance comparison on TPC-H Query 3.  Note not only the improved performance of full compilation, but also the relative memory usage of both instantiations.  All streams except LINEITEM have completed by the 40\% marker and insertions into LINEITEM do not consume any additional memory.}
\label{fig:experiments:tpch3}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_tpch11.pdf}
\caption{Performance comparison on TPC-H Query 11.  The two techniques perform similarly, because for a two-way join full compilation only requires a single recursive step, and fixed (and small) size aggregation.}
\label{fig:experiments:tpch11}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
%\includegraphics[width=3.4in]{../graphs/graphs/unified_ssb4.pdf}
\caption{Performance comparison on SHIPPING.}
\label{fig:experiments:ssb4}
\end{center}
\end{figure}

We first analyze the performance of our compiler on three equijoin queries built on the TPC-H benchmark .  TPC-H Query 3 (Figure \ref{fig:experiments:tpch3}) is a 3-way select-project-join-aggregate.  TPC-H Query 11 (Figure \ref{fig:experiments:tpch11}) is the simplest query of the three, a 2-way equi-join on a one-to-many relationship (SUPPLIER to PARTSUPP) with bounded fanout.  SHIPPING (Figure \ref{fig:experiments:ssb4}) is a 7-table join with a join-width of 6.  

Our compiler recurses only once on TPC-H Query 11.  As a consequence, the result is nearly equivalent to IVM\footnote{We pre-aggregate the materializations of SUPPLIER and PARTSUPP, but this is only a minor improvement in practice due to the bounded fanout of this query}.  

Both TPC-H Query 3 and SHIPPING demonstrate a substantial performance increase over IVM.  The one-to-one, and bounded fanout one-to-many relationships between elements of many of these queries are actually advantageous to the IVM implementation -- each insertion only triggers a limited number of reads.  In spite of this, incrementally maintaining the (aggregate) delta queries results in a net reduction in the amount of work required -- especially in a large query like SHIPPING.

Also note the memory usage of TPC-H Query 3.  During the final stretch starting by the 40\% marker, the all streams have been exhausted except for LINEITEM.  The final aggregate's group-by columns are drawn purely from the order table, so insertions into LINEITEM only update aggregate values that were already  allocated by the corresponding ORDER.  Consequently, memory usage plateaus for full compilation, while the IVM implementation must continue to store each row.

\subsection{Nested Subqueries}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_tpch22.pdf}
\caption{Performance comparison on TPC-H Query 22.  Execution of the IVM implementation was terminated after 60 minutes.  The much smaller CUSTOMERS stream completes around the 18\% marker, leaving only the O(1) insert cost of insertions into ORDERS.  Each insertion into ORDERS only updates a per-customer aggregate, and consumes no additional memory.}
\label{fig:experiments:tpch22}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_vwap.pdf}
\caption{Performance comparison on VWAP.  Execution of the IVM implementation was terminated after 60 minutes.  The IVM implementation must repeatedly re-evaluate a correlated nested subquery, while the fully compiled version incrementally maintains pre-computed versions of the query for a fixed domain of already encountered values.  The unbounded memory growth is discussed in Section \ref{sec:experiments:future}.}
\label{fig:experiments:vwap}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_brokervariance.pdf}
\caption{Performance comparison on BROKERVARIANCE.  Execution of the IVM implementation was terminated after 60 minutes.  Although this is a 2-way join like TPCH Query 11, the join relationship is many-to-many and requires a linear amount of work in IVM.  Conversely, the fully compiled version stores only the aggregate results and requires a constant amount of work for each insertion.}
\label{fig:experiments:brokervariance}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
%\includegraphics[width=3.4in]{../graphs/graphs/unified_tpch17.pdf}
\caption{Performance comparison on TPC-H Query 17}
\label{fig:experiments:tpch17}
\end{center}
\end{figure}

Figures \ref{fig:experiments:tpch22}, \ref{fig:experiments:vwap}, \ref{fig:experiments:brokervariance}, and \ref{fig:experiments:tpch17} illustrate the performance of our compiler on several queries with nested aggregates.  

Of these, TPC-H Query 22: queries with selection conditions based on a nested aggregate query over CUSTOMER\footnote{TPC-H Query 22 also has a nested lookup, which is constant-time in both IVM and full compilation.}.  IVM recomputes the nested aggregate is recomputed for every insertion, and must re-evaluate whether each customer contributes to the result set -- an approach that is twice linear at best, quadratic at worst.  Full compilation must still iterate over all customers to determine whether they contribute to the result set, but can do so for only customers known not to satisfy the second nested aggregate query predicate.

VWAP has a selection condition based on two nested aggregate queries.  One of the nested aggregates has an inequality condition over a variable not bound inside the expression.  As in TPC-H Query 22, these aggregates are recomputed on every update.  The nested aggregate with an inequality condition over an externally bound variable is of interest.  Because the domain of the externally bound variable is determined outside of the nested aggregate, the fully compiled query must still re-evaluate the nested query every time it encounters a bid with a price that it has not seen before.  However, the domain of prices is bounded, so after an initial ramp up process (that occurs while the size of the table is small) the fully compiled query can incrementally maintain the query output.

Although it does not contain a nested aggregate, the performance of BROKERVARIANCE follows a pattern similar to the prior two queries.  This is not surprising -- materializing the first order delta has the same effect as materializing the correlated aggregate into an incrementally maintained lookup table.  Furthermore, unlike TPC-H Query 11 (Figure \ref{fig:experiments:equijoin}a,c), the join relationship is many-to-many and the number of matches grows over time.  Consequently, IVM must do more work with each iteration, while the fully compiled query's work remains constant.

TPC-H Query 17 contains both a nested aggregate and a two-way join.  As in the prior two queries, incrementally maintaining the nested aggregate makes insertions into the LINEITEM table constant-time rather than linear.  However, even in the fully compiled query, insertions into the PART table must still iterate over all matching LINEITEM entries to compute the update to the query result.  In practice full compilation would perform even better, as the TPC-H specification defines the join key as a foreign key dependency from LINEITEM to PART, while the random ordering of insertions in our tests results in some LINEITEMs being inserted before their corresponding PART.

\subsection{Memory, Extraction, and Future Work}
\ref{sec:experiments:future}
\begin{figure}
\begin{center}
%\includegraphics[width=3.4in]{../graphs/graphs/unified_tpch18.pdf}
\caption{Performance comparison on TPC-H Query 18}
\label{fig:experiments:tpch18}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
%\includegraphics[width=3.4in]{../graphs/graphs/unified_serverload.pdf}
\caption{Performance comparison on SERVERLOAD}
\label{fig:experiments:serverload}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_pricespread.pdf}
\caption{Performance comparison on PRICESPREAD.  The performance and memory plateaus result from a portion of the trace from about 0.001\% to 0.01\%, where a single order is repeatedly placed and revoked.}
\label{fig:experiments:pricespread}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
%\includegraphics[width=3.4in]{../graphs/graphs/unified_missedtrades.pdf}
\caption{Performance comparison on MISSEDTRADES.  The performance and memory plateaus result from a portion of the trace from about 0.001\% to 0.01\%, where a single order is repeatedly placed and revoked.}
\label{fig:experiments:missedtrades}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_axfinder.pdf}
\caption{Performance comparison on AXFINDER}
\label{fig:experiments:axfinder}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3.4in]{../graphs/graphs/unified_brokerspread.pdf}
\caption{Performance comparison on BROKERSPREAD}
\label{fig:experiments:brokerspread}
\end{center}
\end{figure}

It is important to understand not only where our compiler succeeds, but its limitations of are.  We now consider three cases where the observed performance of our technique does not match up with our expectations, and consider both why the problem occurs and how one might approach a solution.

The first case of poor performance we consider is TPC-H Query 18, a relatively straightforward query with a three-way join and an easily extractable nested subquery.  In spite of this simplicity, the query performs badly -- the query performs better at depths 0 and 1.  The reason for this poor performance is our join ordering heuristic: The trigger that updates the query result must compute a join between the delta of the extracted nested subquery (aggregated over orderkey) and a materialized representation of CUSTOMER JOIN ORDER JOIN LINEITEM (aggregated over custkey and orderkey).  Not knowing about the one-to-many relationship between custkey and orderkey, we iterate over the materialized join first and effectively iterate over all orders placed so far.  Join ordering is a well studied problem in the database community, and the solution to this problem is purely an engineering challenge (albeit a big one; we have yet to see a stable, publicly available in-memory database compiler).  

The second case is best illustrated by SERVERLOAD, a query with a comparison over a nested aggregate.  By all rights, this query should perform as well as TPC-H 22, VWAP, and BROKERVARIANCE (Figure \ref{fig:experiments:nestedgood}).  The difficulty here is related to domain maintenance \todo{Do we discuss this elsewhere in the paper?  Backreference... this is not the place to be discussing it}.  In effect, our runtime is unable to properly garbage collect deleted entries in one of the generated lookup tables, resulting in a progressively growing workload on every insertion.  

This same issue affects both PRICESPREAD and MISSEDTRADES.  Apart from a stretch of updates (2000 to 25000) in the stock market trace where the same order is repeatedly placed and revoked -- an apparent denial of service attack or broken automated trading system\footnote{It should be noted that our performance characteristics during the denial of service attack are even better than during normal operations} -- the query performance follows a very similar performance curve.

The final case of performance issues is seen in both AXFINDER and BROKERSPREAD, both two-way inequality joins.  Our aggressive extraction heuristic attempts to materialize the entire delta query, which for inequality joins includes an unbound variable.  In such cases, the extracted expression is incrementally maintained for every encountered valuation of the unbound variable.  Thus, each change to the extracted expression requires an iteration over all previously encountered values.  In most cases, most of the state kept for each row in this output can be pre-aggregated and is typically quite small.  However, in the case of these two queries, these tables are each approximately the size of both input tables.  An improved, data-dependent extraction heuristic could identify such situations and compute the inequality join inline -- effectively doing what IVM does.  Alternatively, the entire materialized delta could be incrementally maintained more efficiently using datastructures\cite{range trees} suited to lookups over inequalties.


\subsection{Varying Depths}
\begin{figure}
\begin{center}
\includegraphics[width=3in]{../graphs/graphs/depth_ssb4.pdf}
\caption{Average processing rate as a function of compilation depth on SHIPPING.}
\label{fig:experiments:ssb4depth}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{../graphs/loc_table.tex}
\caption{Lines of Code Per Query}
\label{fig:experiments:loc}
\end{center}
\end{figure}