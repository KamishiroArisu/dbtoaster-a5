require 'util.rb'
$:.push("/usr/lib/ruby/user-gems/1.8/gems/gnuplot-2.3.6/")
require 'lib/gnuplot.rb'

$num_threads = 16;
$queries = {
  "axfinder" => {
    :datafile      => "finance/axfinder.sql",
    :max_plot_rate => 800,
    :max_plot_mem  => 60,
    :representatives => ["depth_infty", "depth_1", "depth_0"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates  => 2540000,
    :title => "AXF"
  },
  "brokerspread" => {
    :datafile      => "finance/brokerspread.sql",
    :max_plot_rate => 300,
    :max_plot_mem  => 60,
    :representatives => ["depth_infty", "depth_1", "depth_0"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates  => 2540000,
    :title => "BSP"
  },
  "brokervariance" => {
    :datafile      => "finance/brokervariance.sql",
    :max_plot_rate => 200000,
    :max_plot_mem  => 40,
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000000,
    :rate_mult     => 1000,
    :timescale     => :minutes,
    :total_updates  => 1400000,
    :title => "BSV"
  },
  "missedtrades" => {
    :datafile      => "finance/missedtrades.sql",
    :max_plot_rate => 60,
    :max_plot_mem  => 2,
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates  => 2540000,
    :title => "MST"
  },
  "pricespread" => {
    :datafile      => "finance/pricespread.sql",
    :max_plot_rate => 500,
    :max_plot_mem  => 400.0/1024.0,
    :progress_code => " 0,0.003,0.019",
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000,
    :mem_mult      => :KB,
    :timescale     => :minutes,
    :total_updates  => 2540000,
    :title => "PSP"
  },
  "serverload" => {
    :datafile      => "serverload.sql",
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :max_plot_rate => 400,
    :max_plot_mem  => 6,
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates  => 220000,
    :title => "SVL"
  },
  "vwap" => {
    :datafile      => "finance/vwap.sql",
    :max_plot_mem  => 40,
    :max_plot_rate => 4000,
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000,
    :rate_mult     => 1000,
    :timescale     => :minutes,
    :total_updates  => 1400000,
    :title => "VWAP"
  },
  "ssb4" => {
    :datafile      => "tpch/ssb4.sql -d disable-deletes",
    :max_plot_rate => 400,
    :max_plot_mem  => 12*1024,
    :representatives => ["depth_infty", "depth_1", "depth_0"],
    :tuple_mult    => 1000,
    :mem_mult      => :GB,
    :timescale     => :minutes,
    :total_updates => 786000,
  },
  "tpch3" => {
    :datafile      => "tpch/query3.sql",
    :max_plot_rate => 40000,
    :max_plot_time => 600,
    :max_plot_mem  => 100,
    :representatives => ["depth_infty", "depth_1", "depth_0"],
    :tuple_mult    => 1000,
    :rate_mult     => 1000,
    :timescale     => :minutes,
    :total_updates => 765000
  },
  "tpch11" => { 
    :datafile      => "tpch/query11.sql",
    :max_plot_rate => 80000,
    :max_plot_time => 2,
    :max_plot_mem  => 8,
    :representatives => ["depth_infty", "depth_1", "depth_0"],
    :tuple_mult    => 1000,
    :rate_mult     => 1000,
    :total_updates => 81000
  },
  "tpch17" => { 
    :datafile      => "tpch/query17.sql",
    :max_plot_rate => 100,
    :max_plot_mem  => 24,
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates => 620000
  },
  "tpch18" => { 
    :datafile      => "tpch/query18.sql",
    :max_plot_rate => 100,
    :max_plot_mem  => 600,
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates => 765000
  },
  "tpch22" => { 
    :datafile      => "tpch/query22.sql",
    :max_plot_rate => 500,
    :max_plot_mem  => 1.6,
    :representatives => ["depth_infty", "depth_1_nohash", "depth_0"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates => 165000
  },
  "5gig_tpch3" => {
    :datafile      => "tpch/query3.sql",
    :max_plot_rate => 40000,
    :max_plot_time => 3600,
    :max_plot_mem  => 4096,
    :representatives => ["depth_infty", "depth_1"],
    :tuple_mult    => 1000,
    :rate_mult     => 1000,
    :mem_mult      => :GB,
    :timescale     => :minutes,
    :total_updates => 765000*50
  },
  "5gig_tpch11" => { 
    :datafile      => "tpch/query11.sql",
    :max_plot_rate => 80000,
    :max_plot_time => 100,
    :max_plot_mem  => 400,
    :representatives => ["depth_infty", "depth_1"],
    :tuple_mult    => 1000,
    :rate_mult     => 1000,
    :total_updates => 81000*50
  },
  "5gig_tpch22" => { 
    :datafile      => "tpch/query22.sql",
    :max_plot_rate => 500,
    :max_plot_mem  => 12,
    :representatives => ["depth_infty", "depth_1_nohash"],
    :tuple_mult    => 1000,
    :timescale     => :minutes,
    :total_updates => 165000*50
  }
};
$configurations = [
  ["Full Compilation", "depth_infty"],
  ["Depth 1 (IVM)",        "depth_1"],
  ["Depth 1 (IVM)", "depth_1_nohash"],
  ["Depth 0 (Repeated)",   "depth_0"],
  ["No Functional Opts",   "depth_infty_optsoff"],
]
$conf_titles = $configurations.map {|t,c| [c,t]}.to_h;

def get_mem(bin,heap_file,map)
#  puts "Getting memory usage for #{map} from #{heap_file}";
  m_fn = "#{map}_value_update"
  `pprof --text #{bin} #{heap_file} --focus=#{m_fn} 2>/dev/null`.
    split(/\n/).
    map { |l| if /Total: (.*)$/ =~ l then $1 else nil end }.
    compact[0].gsub(/ /, "")
end

def get_maps(q)
  File.open("bin/#{q}.maps") { |f| f.readlines }.map { |m| m.chomp }
end

def query_maps(testfile) 
  File.open(testfile){ |f| f.readlines }.
  map { |t| t.chomp.sub(/\t/, "_").split(/\t/) }.
  map do |q, tuples, id, heap_f| 
    get_maps(q).map do |m|
       [  q, tuples, 
          "bin/#{q}", 
          "#{File.dirname testfile}/#{heap_f}",
          m
        ]
    end
  end.flatten(1)
end

def get_mem_threaded(testfile)
  query_maps(testfile).subdivide($num_threads).map do |workload|
    Thread.new do
      Thread.current[:ret] = 
        workload.map do |q, tuples, bin, heap, map|
          mem = get_mem(bin,heap,map);
          raise "Invalid memory value #{mem}" unless 
            /([0-9.]*)([a-zA-Z]+)/ =~ mem;
          mem = $1.to_f * (case $2
            when "MB" then 1024 * 1024
            when "KB" then 1024
            when "B" then 1
            else raise "Unknown memory suffix '#{$2}' in #{mem}"
            end)
          puts "#{q} @ #{tuples} #{map}=#{mem.to_i}B";
          [q,tuples,map,mem];
        end
    end
  end.map { |t| t.join[:ret]; }.flatten(1)
end

def get_filename args
  case args
    when Hash then args.keys[0]
    else           args
  end
end

def intermediate_data title
  File.open(title) do |f|
    f.readlines.map { |l| l.chomp.split(/\t/) }
  end
end

def intermediate args
  title = get_filename args;
  file args do
    data = yield.map { |l| l.join("\t") }.join("\n");
    File.open(intermediate_file(title), "w+") { |f| f.write(data) }
  end
end

def plot(args = {})
  file args do
    filename = get_filename args;
    fmt = case filename
        when /\.pdf$/ then "pdf enhanced size 2.2,1.6"
        when /\.ps$/ then "postscript eps enhanced"
        when /\.tex$/ then "epslatex"
        else raise "Unknown plot format"
      end
    puts "gnuplot > #{filename} (#{fmt})"
    
    Gnuplot.open do |gp|
      Gnuplot::Plot.new(gp) do |plot|
        plot.terminal fmt
        plot.output filename;
        if fmt == "pdf enhanced" then
          (1..5).each { |i| plot.style "line #{i} lt 5" }
        end
        $gp_rake_plot = plot;
        yield plot;
      end
    end
  end
end

def dataset(title, with="lines")
  $gp_rake_plot.data << 
    Gnuplot::DataSet.new(yield.unzip) do |ds|
      ds.title = title
      ds.with = with;
    end
end

def tuples_processed(file)
  data =
    File.open(file) do |f|
      f.readlines.
        grep(/([0-9]+) tuples processed at ([0-9]+)s\+([0-9]+)us/) do |l| 
          [l[1].to_i, l[2].to_i, l[3].to_i] 
        end
    end
  start_s  = data[0][1];
  start_us = data[0][2];
  data.map {|tuples,s,us| [(s - start_s)+(us-start_us)*0.000001, tuples] }
end

def tuple_rate(datafile)
  data = tuples_processed(datafile)
  last_t, last_tuples = *(data.shift); rate = 0;
  data.map do |t, tuples|
    rate = (tuples-last_tuples)/(t - last_t) unless (t - last_t) == 0;
    last_t = t
    last_tuples = tuples;
    [tuples, rate]
  end
end

def draw_clustered_bar_plot plot, args
  data = args.fetch(:data).unzip;
  base_offset       = args.fetch(:base_offset,       0);
  interbar_offset   = args.fetch(:interbar_offset,   18);
  intergroup_offset = args.fetch(:intergroup_offset, interbar_offset);
  margins           = args.fetch(:margins,           intergroup_offset);
  bar_width         = args.fetch(:bar_width,         10);
  tic_commands      = args.fetch(:tic_commands,      "");
  label_offset      = args.fetch(:label_offset,      0);
  
  group_offset = base_offset + margins
  group_size = interbar_offset * data.length + intergroup_offset;
  plot.boxwidth bar_width.to_s;
  pattern = 0;
  data.zip(args[:dataset_labels]).each do |dataset, dataset_title|
    offset = group_offset - group_size;
    group_offset += interbar_offset;
    
    indices = dataset.map { |i| offset += group_size; }
    plot.data << Gnuplot::DataSet.new([indices,dataset]) do |ds|
      ds.title = dataset_title
      ds.with  = "boxes fill pattern #{pattern += 1}";
    end
  end
  
  label_offset += (group_size+intergroup_offset-margins)/2
  group_offset = base_offset - label_offset;
  plot.xtics "(#{args[:group_labels].map do |label|
    "\"#{label}\" #{group_offset += group_size}";
  end.join(", ")}) scale 0 #{tic_commands}";
  
  plot.xrange "[-10:#{group_offset+label_offset+margins-intergroup_offset}]"
end

def draw_bar_plot plot, args
  plot.key "off"
  args = args.clone
  args[:data] = args[:data].map {|d| [d]}
  args[:dataset_labels] = [""];
  args[:group_labels] = args[:labels];
  
  draw_clustered_bar_plot plot, args
end

plot "graphs/test.pdf" => "rakefile" do |plot|
  plot.yrange "[0:6]"
  draw_clustered_bar_plot plot, 
    :group_labels => ["A", "B", "C"],
    :dataset_labels => ["X", "Y", "Z", "D"],
    :data => [ [1, 2, 3], [2, 3, 4], [3, 4, 5], [5, 6, 7] ];
end

class Numeric
  def to_padded_s(cols)
    tmp = self.to_s;
    if tmp.length < cols then "0"*(cols-tmp.length)+tmp else tmp end
  end

  def to_pretty_s
    tmp = self.abs.to_i;
    ipart = 
      if tmp >= 1000 then
        ret = (tmp % 1000).to_padded_s(3);
        while tmp >= 1000 do
          tmp /= 1000
          ret = "#{
            if tmp >= 1000 then (tmp % 1000).to_padded_s(3) else tmp end
          },#{ret}";
        end
        ret
      else
        ret.to_s
      end
    "#{if self < 0 then "-" else "" end}#{ipart}";
  end
end

def file_data args
  filename = case args
    when Hash then args.keys[0];
    else args
  end
  file args do
    data = yield;
    File.open(filename, "w+") { |f| f.write(data); }
  end
end

query_order = [
  "tpch3", "tpch11", "tpch17", "tpch18", "tpch22", "ssb4", 
#  "serverload",
  "brokervariance", "brokerspread", "axfinder", "pricespread",
    "missedtrades", "vwap", 
];
traditional_engines = ["Esper", "CSPE", "Postgres", "CDB"];


file_data "bakeoff.tex" => ["data/engine-comparison.csv","rakefile"] do
  labels, data = query_order.map do |q|
      args = $queries[q]
      data = ["infty", "0"].map do |d|
        chosen_conf = "depth_#{d}";
        args.fetch(:representatives, []).
          each { |r| chosen_conf = r if /depth_#{d}/ =~ r; }
        
        time, tuples =
          if File.exists? "data/time_#{q}_#{chosen_conf}_0"
          then tuples_processed("data/time_#{q}_#{chosen_conf}_0")[-1];
          else puts "Warning: missing file 'data/time_#{q}_#{chosen_conf}_0'";
               [-1,-1]
          end
        
        if time <= 0 then "XXX" 
        else ((tuples / time)*100.0).round * 0.01 end;
      end
      
      [ if args.has_key? :title 
        then args[:title]
        else q.upcase
        end, 
        data ];
    end.unzip;
  
  good_engines = ["CSPE", "CDB"];
  traditional_data = 
    File.open("data/engine-comparison.csv") {|f| f.readlines }[2..-1].
    map { |l| l = l.chomp.split(/,/); [l.shift, l.map {|v| v.to_f }] }.
    map { |q,d| [ q.downcase.sub(/q/, "tpch"), 
                  [ d[0...traditional_engines.length],
                    d[traditional_engines.length..-1] ] ] }.to_h
  
    data = data.zip(query_order.map do |q|
      if traditional_data.has_key? q then
        engine_data = 
          traditional_engines.zip(traditional_data[q][1]).to_h
        good_engines.map { |e| ((engine_data[e]*100.0).round)*0.01 };
      else
        puts "Yanif's data is missing #{q}";
        good_engines.map { |e| "XXX" };
      end
    end).map { |a,b| a+b };
  
  "\\begin{tabular}{|r|#{"c"*(good_engines.length+2)}|}\\hline \n"+
  ([["Query", "Full Compilation", "Depth 1"]+good_engines]+
  labels.zip(data).map do |label,data|
    ["{\\bf #{label}}"]+data
  end).map { |l| l.join(" & ")+"\\\\ \\hline \n" }.join("") +
  "\\end{tabular}";
end
  


["pdf", "tex", "ps"].each do |fmt|
  plot "graphs/engine_bakeoff.#{fmt}" =>
        ["data/engine-comparison.csv","rakefile"] do |plot|
        
    plot.term "pdf enhanced size 4,2.5" if fmt == "pdf"
    plot.ytics "nomirror"
    traditional_data = 
      File.open("data/engine-comparison.csv") {|f| f.readlines }[2..-1].
      map { |l| l = l.chomp.split(/,/); [l.shift, l.map {|v| v.to_f }] }.
      map { |q,d| [ q.downcase.sub(/q/, "tpch"), 
                    [ d[0...traditional_engines.length],
                      d[traditional_engines.length..-1] ] ] }.to_h
    
    data = query_order.map do |q|
      if traditional_data.has_key? q then
        traditional_data[q][1]
      else
        puts "Yanif's data is missing #{q}";
        traditional_engines.map { |e| 0 };
      end
    end
    
    plot.logscale "y";    
    plot.ylabel "Average Refresh Rate (1/s)";
    plot.bmargin "5";
    
    draw_clustered_bar_plot plot, 
      :group_labels => (query_order.map do |q|
        $queries[q].fetch(:title, q.upcase);
      end),
      :dataset_labels => traditional_engines,
      :data => data,
      :tic_commands => "rotate by -30",
      :bar_width => 15,
      :label_offset => 12,
      :intergroup_offset => 20
  end
  
  plot "graphs/bakeoff.#{fmt}" => 
       ["data/engine-comparison.csv","rakefile"] do |plot|
    depths = ["infty", "1", "0"];
    
    plot.term "pdf enhanced size 5,2.5" if fmt == "pdf"
    plot.logscale "y"
    plot.key "top right"
    plot.ytics "nomirror"
    
    labels, data = query_order.map do |q|
      args = $queries[q]
      data = depths.map do |d|
        chosen_conf = "depth_#{d}";
        args.fetch(:representatives, []).
          each { |r| chosen_conf = r if /depth_#{d}/ =~ r; }
        
        time, tuples =
          if File.exists? "data/time_#{q}_#{chosen_conf}_0"
          then tuples_processed("data/time_#{q}_#{chosen_conf}_0")[-1];
          else puts "Warning: missing file 'data/time_#{q}_#{chosen_conf}_0'";
               [0,0]
          end
        
        if time == 0 then 0 else tuples / time end;
      end
      
      base_rate = if data[2] == 0 then
        puts "Warning: Depth 0 rate = 0 for #{q}, using Depth 1 rate";
        data[1] else data[2] end
      
      [ if args.has_key? :title 
        then args[:title]
        else q.upcase
        end, 
        data.map { |rate| rate / base_rate } ];
    end.unzip
    
#    good_engines = ["CSPE", "CDB"]
#    traditional_data = 
#      File.open("data/engine-comparison.csv") {|f| f.readlines }[2..-1].
#      map { |l| l = l.chomp.split(/,/); [l.shift, l.map {|v| v.to_f }] }.
#      map { |q,d| [ q.downcase.sub(/q/, "tpch"), 
#                    [ d[0...traditional_engines.length],
#                      d[traditional_engines.length..-1] ] ] }.to_h
#    
#    data = data.zip(query_order.map do |q|
#      if traditional_data.has_key? q then
#        engine_data = 
#          traditional_engines.zip(traditional_data[q][1]).to_h
#        good_engines.map { |e| engine_data[e] };
#      else
#        puts "Yanif's data is missing #{q}";
#        good_engines.map { |e| 0 };
#      end
#    end).map { |a,b| a+b };
        
    plot.ylabel "Average Refresh Rate \\n(Relative To Repeated Evaluation)"
    #plot.bmargin "5"
    
    draw_clustered_bar_plot plot, 
      :group_labels => labels,
      :dataset_labels => depths.map { |d| $conf_titles["depth_#{d}"] },# +
                         #good_engines,
      :data => data,
      :tic_commands => "rotate by -30",
      :bar_width => 15,
      :label_offset => 12
  end
  task fmt => "graphs/bakeoff.#{fmt}"
  
  plot "graphs/depth_ssb4.#{fmt}" => "rakefile" do |plot|
    labels, data = 
      [0,1,2,3,4,5,"infty"].map do |d|
        conf = "depth_#{d}#{"_nohash" if d == 1}"
        time, tuples = tuples_processed("data/time_ssb4_#{conf}_0")[-1];
        [ if d == "infty" then "Full Depth" else "  Depth #{d}" end,
          if time == 0 then 0 else tuples / time end
        ]
      end.unzip

    plot.term "pdf enhanced size 3,2.0" if fmt == "pdf"
    plot.ylabel "Processing Rate (Relative to Depth 0)"

    draw_bar_plot plot, 
      :labels => labels,
      :data => data,
      :tic_commands => "rotate by -20",
      :label_offset => 10
  end
  task fmt => "graphs/depth_ssb4.#{fmt}"

  $queries.each do |q,args|
    q_graphs = [];
    
    graph_configs = args.fetch(:representatives, $configurations.unzip[1]);
    alldata = graph_configs.map { |code| "data/time_#{q}_#{code}_0" }
    
    tuple_mult, tuple_mult_txt = 
      if args.has_key? :tuple_mult 
        then [args[:tuple_mult].to_f, " (x#{args[:tuple_mult].to_pretty_s})"] 
        else [1.to_f,""] 
      end;
    time_mult, time_scale = 
      case args.fetch(:timescale, :seconds)
        when :seconds then [1.to_f, "s"]
        when :minutes then [60.to_f, "min"]
        else [1.to_f, "s"]
      end
    
    plot "graphs/time_#{q}.#{fmt}" => alldata do |plot|
      plot.xlabel "Time (#{time_scale})"
      plot.ylabel "Tuples Processed#{tuple_mult_txt}"
      cap_time = false;
      graph_configs.each do |conf_code|
        datafile = "data/time_#{q}_#{conf_code}_0";
        dataset($conf_titles[conf_code]) do
          tuples_processed(datafile).map do |t,tuples| 
            cap_time = cap_time || t > 3600
            [ t.to_f / time_mult,
              tuples.to_f / tuple_mult
            ]
          end
        end
      end
      plot.xrange "[0:#{3600/time_mult}]" if cap_time
    end
    q_graphs.push "graphs/time_#{q}.#{fmt}"
  
    graph_configs.each do |conf_code|
      datafile = "data/time_#{q}_#{conf_code}_0";
      if File.exists? datafile then
        plot "graphs/rate_#{q}_#{conf_code}.#{fmt}" => datafile do |plot|
          plot.xlabel "Tuples Processed"
          plot.ylabel "Refresh Rate (1/s)"
          dataset($conf_titles[conf_code]) { tuple_rate(datafile) }
        end
        q_graphs.push "graphs/rate_#{q}_#{conf_code}.#{fmt}"
      end
    end
    
    plot "graphs/windowedrate_#{q}.#{fmt}" => alldata do |plot|
      plot.xlabel "Tuples Processed#{tuple_mult_txt}"
      plot.ylabel "Refresh Rate (#{tuple_mult.to_i.to_pretty_s}/s)"
      plot.yrange "[0:#{args[:max_plot_rate]/tuple_mult}]" if args.has_key? :max_plot_rate;

      i = 0;
      graph_configs.each do |conf_code|
        datafile = "data/time_#{q}_#{conf_code}_0";
        dataset($conf_titles[conf_code]) do 
          tuple_rate(datafile).map do |tuples, rate| 
            [ (tuples.to_f / tuple_mult), 
              (rate.to_f / tuple_mult)]
          end
          #.window(5) do |w| 
  #          tuples, rate = w.unzip
  #          [tuples[-1], rate.avg]
  #        end
        end
      end
    end
    q_graphs.push "graphs/windowedrate_#{q}.#{fmt}"
    
    ["depth_0", "depth_1", "depth_infty"].each do |depth|
      if File.exists? "data/memory_#{q}_#{depth}.profile" then
        plot "graphs/memory_#{q}_#{depth}.#{fmt}" =>
             "data/memory_#{q}_#{depth}.profile" do |plot|
          
          mem_by_map = Hash.new { |h,k| h[k] = Array.new };
          
          File.open("data/memory_#{q}_#{depth}.profile") { |f| f.readlines }.
            map { |l| l.chomp.split(/\t/) }.
            each do |tuples, map, mem, mempct|
              mem_by_map[map].push [tuples.to_i / tuple_mult.to_i, mem.to_f];
            end
          
          mem_by_map.each do |map, data|
            plot.ylabel "Memory Use (MB)"
            plot.xlabel "Tuples Processed#{tuple_mult_txt}"
            plot.key "off"
            plot.data << Gnuplot::DataSet.new(data.unzip) do |ds|
              ds.with= "lines"
              ds.title = map.gsub(/_/, "");
            end
          end
        end
        q_graphs.push "graphs/memory_#{q}_#{depth}.#{fmt}"
      end
    end
    
    plot "graphs/memory_#{q}.#{fmt}" do |plot|
      graph_configs.each do |config|
        config.sub!(/_nohash/, "");
        
        if File.exists? "data/memory_#{q}_#{config}.profile" then
          mem_by_tuples = Hash.new { |h,k| h[k] = Array.new };
          
          File.open("data/memory_#{q}_#{config}.profile") { |f| f.readlines }.
            map { |l| l.chomp.split(/\t/) }.
            each do |tuples, map, mem, mempct|
              mem_by_tuples[tuples.to_f / tuple_mult.to_f].push mem.to_f
            end
          
          plot.ylabel "Memory Use (MB)"
          plot.xlabel "Tuples Processed#{tuple_mult_txt}"
          
          plot.data << Gnuplot::DataSet.new(
              mem_by_tuples.keys.sort.map do |t|
                [t, mem_by_tuples[t].sum]
              end.unzip) do |ds|
            ds.with = "lines";
            ds.title = $conf_titles[config]
          end
        end
      end
    end
    q_graphs.push "graphs/memory_#{q}.#{fmt}"

    task "#{q}" => q_graphs
    task "#{q}-#{fmt}" => q_graphs do
      sh "open #{q_graphs.join(" ")}"
    end
    
    task fmt => q_graphs
    
  end
  task :all_graphs => fmt;
end

class Array
  def fold(accum = nil)
    each { |i| accum = yield accum, i }
    accum
  end
end

class Hash
  def intersect(other)
    ret = {};
    keys.each do |k|
      ret[k] = yield k, self[k], other[k] if other.has_key? k
    end
    ret;
  end
  
  def to_sorted_a
    keys.sort.map do |k|
      [k, self[k]]
    end
  end
end



$queries.each do |q, args|
  tot_tups = args[:total_updates];
  graph_configs = args.fetch(:representatives, $configurations.unzip[1]);
  extraction_graph_configs = graph_configs;
  extraction_graph_configs +=
    ["depth_2", "depth_3", "depth_4", "depth_5"] if q == "ssb4";

  extraction_graph_configs.map do |config|
    file_data "extracted/memory_#{q}_#{config}" => 
              "data/memory_#{q}_#{config}.profile" do
      puts "Building extracted/memory_#{q}_#{config}"
  
      mem_by_tuples = Hash.new { |h,k| h[k] = Array.new };
  
      File.open("data/memory_#{q}_#{config}.profile") { |f| f.readlines }.
        map { |l| l.chomp.split(/\t/) }.
        each do |tuples, map, mem, mempct|
          mem_by_tuples[tuples.to_f].push mem.to_f
        end
        
      "#% Complete\t#{config}\n" +
      mem_by_tuples.to_sorted_a.
        map { |tuples, mem| [tuples / tot_tups, mem.sum]}.
        map { |row| row.join("\t") }.join("\n");
    end

    file_data "extracted/time_#{q}_#{config}" => 
              "data/time_#{q}_#{config}_0" do
      puts "Building extracted/time_#{q}_#{config}"
  
      last_tuple = 0;
      last_time = 0;
      
      datafile = "data/time_#{q}_#{config}_0";

      "#% Complete\ttime_#{config}\trate_#{config}"+
        if File.exists? datafile then
          tuples_processed(datafile).map do |t,tuples|
            rate = 
              if t - last_time <= 0 then 0
              else (tuples - last_tuple) / (t - last_time)
              end
            last_tuple, last_time = tuples, t;
            [ tuples.to_f / tot_tups, t.to_f, rate.to_f ] 
          end
        else 
          []
        end.map {|l| l.join("\t") }.join("\n");
    end
    
    file "graphs/unified_#{q}.pdf" => 
      ["extracted/time_#{q}_#{config}", "extracted/memory_#{q}_#{config}"]
    
  end
  
  file "graphs/unified_#{q}.pdf" => "rakefile" do
    IO.popen("gnuplot", "w") do |gp|
      gp.puts "set term pdf enhanced size 1.9,2.2";
      gp.puts "set output 'graphs/unified_#{q}.pdf'";
      gp.puts "set multiplot";
      gp.puts "set bmargin 0";
      gp.puts "set tmargin 0";
      
      time_mult, time_scale = 
        case args.fetch(:timescale, :seconds);
          when :minutes then [60, "min"]
          when :seconds then [1,  "s"]
        end
      max_time_y = if args.has_key? :max_plot_time then
          args[:max_plot_time].to_f
        else
          [graph_configs.map do |cfg|
            File.open("extracted/time_#{q}_#{cfg}") {|f|f.readlines[1..-1]}.
              map { |r| r.split(/\t/)[1].to_f }.max
          end.max, 3600].min
        end / time_mult
      mem_scale = args.fetch(:mem_mult, :MB)
      mem_mult = case mem_scale
        when :B then 1024.0 * 1024.0
        when :KB then 1024.0
        when :MB then 1.0
        when :GB then 1.0 / (1024.0)
        else raise "Unknown memory multiplier #{mem_mult}"
      end
      max_mem_y = if args.has_key? :max_plot_mem then
          args[:max_plot_mem].to_f
        else
          graph_configs.map do |cfg|
            File.open("extracted/memory_#{q}_#{cfg}") {|f|f.readlines[1..-1]}.
              map { |r| r.split(/\t/)[1].to_f }.max
          end.max
        end.to_f * mem_mult.to_f
      rate_mult = args.fetch(:rate_mult, 1);
      rate_scale = "#{rate_mult}/s";
      max_rate_y = args[:max_plot_rate] / rate_mult;
      
      max_completion_x = 
          [graph_configs.map do |cfg|
            File.open("extracted/memory_#{q}_#{cfg}") {|f|f.readlines[-1]}.
              split(/\t/)[0].to_f
          end.max, 1].min;
      
      graph_style = lambda do |i, file|
        filedata = File.open(file) { |f| f.readlines };
        max_frac_completed = filedata[-1].chomp.split(/\t/)[0].to_f;
        total_pts = (filedata.length - 1).to_f;
        # 25 points total across the width
        pt_scaling = (total_pts * max_completion_x) / 
                     (50.0 * max_frac_completed);

        case i
          when 0 then "linespoints ps 1 pi #{pt_scaling}"
          when 1 then "linespoints ps 0.7 pi #{pt_scaling}"
          when 2 then "linespoints ps 0.7 pi #{pt_scaling}"
          else "lines"
        end
      end
      
      gp.puts "set xtics format '' #{
        args[:progress_code] if args.has_key? :progress_code
      }";
      gp.puts "set xrange [0:#{max_completion_x}*1.1]"
      gp.puts "set lmargin #{args.fetch(:lmargin, 8)}";
      gp.puts "set ylabel 'Time (#{time_scale})'";
      gp.puts "set key top left";
      gp.puts "set size 1,0.30";
      gp.puts "set origin 0,0.68";
      gp.puts "set yrange [#{-0.05 * max_time_y}:#{max_time_y*1.1}]";
      gp.puts "set ytics 0,#{max_time_y / 4.0},#{max_time_y}"
      gp.puts "plot #{
        i = -1;
        graph_configs.map do |cfg| 
          file = "extracted/time_#{q}_#{cfg}";
          "'#{file}' using 1:($2/#{time_mult}) "+
          "with #{graph_style.call(i+=1, file)} "+
          "title '#{$conf_titles[cfg]}'"
        end.join(", ")
      }";

      gp.puts "set ylabel 'Refreshes (#{rate_scale})'";
      gp.puts "set yrange [#{-0.05 * max_rate_y}:#{max_rate_y*1.1}]";
      gp.puts "set ytics 0,#{(max_rate_y) / 4.0},#{(max_rate_y)}"
      gp.puts "set size 1,0.33";
      gp.puts "set origin 0,0.35";
      gp.puts "set key off";
      gp.puts "plot #{
        i = -1;
        graph_configs.map do |cfg| 
          file = "extracted/time_#{q}_#{cfg}";
          "'#{file}' using 1:($3/#{rate_mult}) "+
          "with #{graph_style.call(i+=1, file)} "+
          "title '#{$conf_titles[cfg]}'"
        end.join(", ")
      }";
      
      gp.puts "set ylabel 'Memory (#{mem_scale})'";
      gp.puts "set yrange [#{-0.05 * max_mem_y}:#{max_mem_y*1.1}]";
      gp.puts "set ytics 0,#{max_mem_y / 4.0},#{max_mem_y}"
      gp.puts "set size 1,0.35";
      gp.puts "set origin 0,0.00";
      gp.puts "set xlabel 'Fraction of Stream Trace Processed'"
      gp.puts "set bmargin 3";
      gp.puts "set xtics format \"%g\" #{
        args[:progress_code] if args.has_key? :progress_code
      }";
      gp.puts "plot #{
        i = -1;
        graph_configs.map do |cfg| 
          file = "extracted/memory_#{q}_#{cfg}";
          "'#{file}' using 1:($2*#{mem_mult}) "+
          "with #{graph_style.call(i+=1, file)} "+
          "title '#{$conf_titles[cfg]}'"
        end.join(", ")
      }";
      gp.puts "unset multiplot";
      
    end
  end

  task :unified => "graphs/unified_#{q}.pdf" do
#    sh "open graphs/unified_#{q}.pdf"
  end
end

["tpch3", "tpch11"].each do |q|
  file_data "extracted/scaling_#{q}" do
    [ ["100 MB", ""], 
      ["500 MB", "500meg_"],
      ["1 GB", "1gig_"],
      ["5 GB", "5gig_"],
      ["10 GB", "10gig_"]
    ].map do |title,size|
      ( [title] + ["infty", 1].map do |d|
          file = "data/time_#{size}#{q}_depth_#{d}_0";
          puts "Reading #{file}";
          time, tuples = tuples_processed(file)[-1];
        end.map { |time,tuples| (tuples.to_f / time.to_f) }
      ).join("\t");
    end.join("\n");
  end
  
  task "graphs/scaling.pdf" => ["extracted/scaling_#{q}"];

  plot "graphs/scaling_#{q}.pdf" => 
       ["rakefile","extracted/scaling_#{q}"] do |plot|
    labels, data = 
      File.open("extracted/scaling_#{q}"){|f| f.readlines}.
        map {|l| l = l.chomp.split(/\t/); 
                 [l.shift,l.map{|y|y.to_f/1000}] }.unzip;

    plot.ylabel "Rate (1000/s)"
    case q
      when "tpch3" then
        plot.yrange "[0:32]"
      when "tpch11" then
        plot.yrange "[0:80]";
    end
  
    draw_clustered_bar_plot plot, 
      :group_labels => labels,
      :dataset_labels => ["Full Compilation", "Depth 1"],
      :data => data,
      :tic_commands => "scale 0 rotate by -30",
      :bar_width => 35,
      :label_offset => -8
  end  
end

plot "graphs/scaling.pdf" => "rakefile" do |plot|
  labels, data = 
    ["tpch3", "foo", "tpch11"].map do |q|
      if q == "foo" then
        ["", [[0,0]]];
      else
        File.open("extracted/scaling_#{q}"){|f| f.readlines}.
        map {|l| l = l.chomp.split(/\t/); 
                 [l.shift,l.map{|y|y.to_f/1000}] }.unzip
      end
    end.unzip
  
  data = data.flatten(1);
  labels = labels.flatten(1);
  
  plot.term "pdf enhanced size 3,1.6"
  plot.key "top left"
  
  plot.ylabel "Refreshes (1000/s)"
  
  plot.bmargin "4"
  plot.label "'TPCH Query 3' at #{150},-18 center"
  plot.label "'TPCH Query 11' at #{500},-18 center"
  plot.yrange "[0:65]"
  draw_clustered_bar_plot plot,
    :group_labels => labels,
    :dataset_labels => ["Full Compilation", "Depth 1"],
    :data => data,
    :tic_commands => "scale 0 rotate by -30",
    :bar_width => 14,
    :label_offset => 10
  plot.xrange "[-20:620]"
  
  vbar = 300;
  plot.data << Gnuplot::DataSet.new([[vbar,vbar], [0,70]]) do |ds|
    ds.with = "lines lc -1 lw 4"
    ds.title = ""
  end
end


file "tuple_count.dat" => "rakefile" do
  tuples = Dir.entries("data").
    delete_if { |f| f[0] == '.'[0] }.
    map do |f|
      max_processed = `cat data/#{f} | grep "tuples processed at" | tail -n 1`
      if /^([0-9]+)/ =~ max_processed
      then "#{f}\t#{$1}"
      else raise "Error: Can't extract tuple count from #{f}";
      end
    end.join("\n") + "\n"
  File.open("tuple_count.dat", "w+") { |f| f.write(tuples); }
end

task :default => :pdf;

file "graphs.tgz" => :all_graphs do
  sh "tar -zcvvf graphs.tgz graphs"
end

def dbt_loc(q_file, args)
  cmd = "../../../dbtoaster/compiler/alpha4/dbtoaster";
  script = "../../../dbtoaster/compiler/alpha4/test/sql/#{q_file}";
  puts "Getting LoC for #{q_file} '#{args}'"
  `#{cmd} #{args} #{script} | wc -l`.to_i
end


file_data "extracted/loc_ssb4_depth" do
  [1, 2, 3, 4, 5, "infty"].map do |d|
    depth_flag = if d == "infty" then "" else "--depth #{d}" end
    [ "depth_#{d}",
      dbt_loc("tpch/ssb4.sql", "-d disable-deletes #{depth_flag}")
    ].join("\t");
  end.join("\n");
end

class Float
  def sig_figs(n)
    if self == 0.0 then self
    else
      mult = (10.0 ** (Math.log10(self).ceil.to_f - n.to_i.to_f))
      (self / mult).round * mult;
    end
  end
end

file_data "ssb4_depth_table.tex" => ["rakefile", "extracted/loc_ssb4_depth"] do
  loc = File.open("extracted/loc_ssb4_depth"){|f|f.readlines}.
          map { |l| l.chomp.split(/\t/); }.to_h;
  
  depths = [1, 2, 3, 4, 5, "infty"];
  "\\begin{tabular}{|r|#{depths.map{|d|"c|"}}}\\hline\n" +
[ "{\\bf Depth}", "Avg Rate",     "Avg Memory", "Lines of","Number of\\\\\n",
                    "(refreshes/s)","per Tuple",  "Code",    "Views"
  ].join(" & ") + "\\\\ \\hline\n" +depths.map do |d|
    conf = "depth_#{d}#{"_nohash" if d == 1}"
    time, tuples = tuples_processed("data/time_ssb4_#{conf}_0")[-1];
    mem_file = "extracted/memory_ssb4_#{conf}";
    mem = if File.exists? mem_file 
          then File.open(mem_file) {|f| f.readlines[-1]}.
                  split(/\t/)[1].to_f * 1e6 / tuples.to_f
          else puts "Missing [[#{mem_file}]]"; 0
          end
    ["B", "KB", "MB", "GB"].each do |suffix|
      if mem < 1024 then
        mem = "#{mem.to_f.sig_figs(3)} #{suffix}"; break;
      else
        mem /= 1024;
      end
    end    
    
    mapfile = 
      "data/ssb4_depth_#{d}_#{
        if d == "infty" then "noopt" else "fullopt" end
      }.maps"
    
    rate = (if time == 0 then 0 else tuples / time end).to_f.sig_figs(3)
    
    [ if d == "infty" then "Full" else d.to_s end,
#      tuples,
      rate,
      mem,
      loc["depth_#{d}"],
      `cat #{mapfile} | wc -l`.chomp
    ]
  end.map do |row|
    "#{row.join(" & ")} \\\\ \\hline \n"
  end.join("") +
  "\\end{tabular}"
end

loc_configurations = 
  [ ["Infinite Depth", ""],
    ["Depth 1 with Hash Joins", "--depth 1 -f cse -f breduce -f hashds"],
    ["Depth 1 without Hash Joins", "--depth 1"],
    ["Depth 0 with Hash Joins", "--depth 0 -f cse -f breduce -f hashds"],
    ["Depth 0 without Hash Joins", "--depth 0"] ];

file "loc_table.tex" do
  File.open "loc_table.tex", "w+" do |f|
    f.puts("\\begin{tabular}{|l|#{loc_configurations.map { |x| "c|"}}}\\hline");
    f.puts("\\ & #{loc_configurations.unzip[0].join(" & ")} \\\\\\hline");
    $queries.keys.
      delete_if { |q| /5gig/ =~ q }.
      map do |q|
      q_file = $queries[q][:datafile];
      f.puts("#{q} & #{
        loc_configurations.map do |title, args|
          cmd = "../../../dbtoaster/compiler/alpha4/dbtoaster";
          script = "../../../dbtoaster/compiler/alpha4/test/sql/#{q_file}";
          ret = `#{cmd} #{args} #{script} | wc -l`.to_i
          puts "#{q} : #{title} : #{ret}"
          ret
        end.join(" & ")
        } \\\\\\hline"
      );
    end
    f.puts("\\end{tabular}");
  end
end

# scp damsel:/damsl/projects/dbtoaster/results/big/memory_ssb4_depth_1.profile data/