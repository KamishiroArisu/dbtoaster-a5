<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>DBToaster</title>

<link rel="stylesheet" type="text/css" href="style.css" />

</head><body>

<div class="wrapper">
<h1>DBToaster User Reference</h1>

<ul>
  <li>The DBToaster Compiler
    <ul>
      <li><a href="#quickstart">Quickstart Guide</a></li>
      <li><a href="#commandline">Command Line Reference</a></li>
      <li><a href="#dbtsql">DBT-SQL Reference</a></li>
      <li><a href="#standardadaptors">Standard Adaptors Reference</a></li>
      <li><a href="#optimization">Optimization and Heuristics Features</a></li>
    </ul>
  </li>
  
  <li><a href="dbt_c++.html">DBToaster C++</a>
    <ul>
      <li><a href="dbt_c++.html#quickstart">Quickstart Guide</a></li>
      <li><a href="dbt_c++.html#apiguide">C++ API Guide</a></li>
      <li><a href="dbt_c++.html#codereference">Generated Code Reference</a></li>
    </ul>
  </li>
  
  <li><a href="dbt_scala.html">DBToaster Scala</a>
    <ul>
      <li><a href="dbt_scala.html#quickstart">Quickstart Guide</a></li>
      <li><a href="dbt_scala.html#generatedcode">Generated Code Reference</a></li>
    </ul>
  </li>
</ul>

<h2><a name="quickstart">Quickstart Guide</a></h2>
<p>
DBToaster operates in three modes: (1) Interpreter mode, which compiles and processes queries internally, within the DBToaster binary.  (2) Standalone Binary mode, which compiles queries into binaries.  (3) Source Code mode which compiles queries into datastructures that can be linked into and instantiated within separate projects.
</p>

<h3>Interpreter Mode</h3>
<p>
To use DBToaster in interpreter mode, invoke it with the <tt>-r</tt> flag and one or more SQL query files.  The output of all queries in the file will be printed once all data has been processed.  If any of the queries do not terminate (e.g., one or more data sources are sockets), then pressing control-c will terminate the process and print the most recent query results.

<div class="codeblock">
$&gt; dbtoaster -r test/queries/simple/rst.sql
Processing time: 0.0309669971466
AtimesD: 1.87533670489e+13
</div>
</p>

<h3>Standalone Binary mode</h3>
<p>
To use DBToaster to create a standalone binary, invoke it with the <tt>-c [binary name]</tt> flag.  The binary can be invoked directly.  Like the interpreter, it will print the results of all queries once all data has been processed.  </p>

<div class="codeblock">
$&gt; dbtoaster test/queries/simple/rst.sql -c rst
$&gt; ./rst
&lt;?xml version="1.0" encoding="UTF-8" standalone="yes" ?&gt;
&lt;!DOCTYPE boost_serialization&gt;
&lt;boost_serialization signature="serialization::archive" version="9"&gt;
&lt;ATIMESD&gt;18753367048934&lt;/ATIMESD&gt;
&lt;/boost_serialization&gt;
</div>

<p>
Note that in order to compile binaries, DBToaster will invoke g++.  DBToaster relies on pthreads, several Boost libraries ("program_options", "serialization", "system", "filesystem", "chrono", and "thread"), and a custom DBToaster library.  These must all be in your binary, include, and library search paths.  The -I and -L flags may be used to pass individual include and library paths (respectively) to g++, or the environment variables DBT_HDR, and DBT_LIB may be used to store a colon-separated list of search paths.</p>

<p>
To produce a scala binary, invoke dbtoaster with <tt>-l scala</tt>, and the <tt>-c [binary name]</tt> flag as above.  DBToaster will produce <tt>[binary name].jar</tt>, which can be run using java as a normal scala program.
</p>

<div class="codeblock">
$&gt; dbtoaster test/queries/simple/rst.sql -l scala -c rst
$&gt; java -cp [path_to_dbt_lib]:[path_to_scala_lib] -jar rst.jar
&lt;?xml version="1.0" encoding="UTF-8" standalone="yes" ?&gt;
&lt;!DOCTYPE boost_serialization&gt;
&lt;boost_serialization signature="serialization::archive" version="9"&gt;
&lt;ATIMESD&gt;18753367048934&lt;/ATIMESD&gt;
&lt;/boost_serialization&gt;
</div>

<h3>Source Code Mode</h3>
<p>DBToaster's primary role is the construction of code that can be linked in to existing applications.  To generate a source file in C++ or Scala, invoke it with <tt>-l [language]</tt>, replacing <tt>[language]</tt> with <tt>cpp</tt> or <tt>scala</tt>.  If the optional <tt>-o</tt> flag is used to direct the generated code into a particular file, the target language will be auto-detected from the file suffix (".scala" for Scala, and ".h", ".hpp", or ".cpp" for C++).</p>

<div class="codeblock">
$&gt; dbtoaster test/queries/simple/rst.sql -o rst.hpp
$&gt; dbtoaster test/queries/simple/rst.sql -o rst.scala
$&gt; ls
rst.hpp      rst.scala
</div>

See the individual target language documentation pages for details.

<hr/>
<h2><a name="commandline">Command-Line Reference</a></h2>
<div class="codeblock">
$&gt; dbtoaster [options] &lt;input file 1&gt; [&lt;input file 2&gt; [...]]
</div>

<h3>Command Line Options</h3>
<dl>
<dt class="code">-c &lt;target file&gt;</dt>
<dd>Compile the query into a standalone binary.  By default, the C++ code generator will be used with G++ to generate the binary.  An alternate compiled target language (currently, C++, OCaml, or Scala) may be selected using the <tt>-l</tt> flag.</dd>

<dt class="code">-d &lt;debug mode&gt;</dt>
<dd>Activate the specified debugging mode.  These should generally not be used by end users, but documentation for developers is provided below.</dd>

<dt class="code">-i &lt;language&gt;</dt>
<dd>Specify the language of the input files.  By default, this language will be auto-detected from the file extensions, or assumed to be SQL if the compiler can not guess it.</dd>

<dt class="code">-l &lt;language&gt;</dt>
<dd>Compile the query into the specified target language (see below for a list of valid languages).  By default, the query will be compiled to M3.</dd>

<dt class="code">-o &lt;output file&gt;</dt>
<dd>Redirect the compiler's output to the specified file.  If used in conjunction with <tt>-c</tt>, the source code for the compiled binary will be directed to this file.  Passing in <tt>-</tt> as the output file will direct output to stdout.  By default, output is directed to stdout, or discarded if the <tt>-c</tt> flag is used.</dd>

<dt class="code">-r</dt>
<dd>Run the query (queries) in interpreter mode.</dd>
</dl>

<h3>Supported Languages</h3>
<center>
<table border=1>
  <tr>
    <th align="center">Language</th>
    <th align="center">Commandline Name</th>
    <th align="center">Valid for Input/Output</th>
    <th align="center">Description</th>
  </tr>

  <tr>
    <td>DBT Relational Calculus</td>
    <td class="code">calc</td>
    <td>input/output</td>
    <td>DBToaster's internal query representation.  This is a direct translation of the input queries.</td>
  </tr>

  <tr>
    <td>Compilation Plan</td>
    <td class="code">plan</td>
    <td>output-only</td>
    <td>A materialization plan: a list of datastructures required to incrementally maintain the input queries.</td>
  </tr>

  <tr>
    <td>M3</td>
    <td class="code">m3</td>
    <td>input/output</td>
    <td>A map-mantenance messages program.  This is the set of triggers (written in DBT Relational Calculus) that will incrementally maintain the input queries and all supporting datastructures.</td>
  </tr>

  <tr>
    <td>K3</td>
    <td class="code">k3</td>
    <td>input/output</td>
    <td>The execution plan generated for an M3 program.  This is a simple functional language that admits a set of useful functional optimizations.</td>
  </tr>

  <tr>
    <td>OCaml</td>
    <td class="code">ocaml</td>
    <td>output/compiled</td>
    <td>An OCaml implementation of the K3 execution plan.</td>
  </tr>

  <tr>
    <td>C++</td>
    <td class="code">cpp</td>
    <td>output/compiled</td>
    <td>A C++ implementation of the K3 execution plan.</td>
  </tr>

  <tr>
    <td>Scala</td>
    <td class="code">scala</td>
    <td>output/compiled</td>
    <td>A Scala implementation of the K3 execution plan.</td>
  </tr>

</table>
</center>

<h3>Examples</h3>

To run the query <tt>rst.sql</tt> in the interpreter:
<div class="codeblock">
$&gt; dbtoaster -r rst.sql
Processing time: 0.0424609184265
ATIMESD: 18753367048934
</div>

To compile the query <tt>rst.sql</tt> using the C++ code generator and produce a binary named <tt>rst</tt>:
<div class="codeblock">
$&gt; dbtoaster rst.sql -c rst
$&gt; ./rst
&lt;?xml version="1.0" encoding="UTF-8" standalone="yes" ?&gt;
&lt;!DOCTYPE boost_serialization&gt;
&lt;boost_serialization signature="serialization::archive" version="9"&gt;
&lt;ATIMESD&gt;18753367048934&lt;/ATIMESD&gt;
&lt;/boost_serialization&gt;
</div>

To compile the query <tt>rst.sql</tt> using the C++ code generator, put the source in the file "rst.cpp" and produce a binary named <tt>rst</tt>:
<div class="codeblock">
$&gt; dbtoaster rst.sql -o rst.cpp -c rst
</div>

To compile the query <tt>rst.sql</tt> using the Scala code generator and produce a binary named <tt>rst</tt>:
<div class="codeblock">
$&gt; dbtoaster rst.sql -l scala -c rst
</div>

<hr/>
<h2><a name="dbtsql">DBT-SQL Reference</a></h2>

<h3 class="code">CREATE</h3>
<center>Declare a relation for use in the query.</center>
<div class="codeblock">
create_statement := 
&nbsp;&nbsp;CREATE { TABLE | STREAM } &lt;name&gt; ( &lt;schema&gt; ) [&lt;source_declaration&gt;]

schema := [&lt;var_1&gt; &lt;type_1&gt; [, &lt;var_2&gt; &lt;type_2&gt; [, ...]]]

source_declaration := source_stream source_adaptor

source_stream := 
&nbsp;&nbsp;FROM FILE '&lt;path&gt;' {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FIXEDWIDTH &lt;bytes_per_row&gt;
&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;LINE DELIMITED
&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;'&lt;delim_string&gt;' DELIMITED
&nbsp;&nbsp;} 

source_adaptor := 
&nbsp;&nbsp;&lt;adaptor_name&gt; (
&nbsp;&nbsp;&nbsp;&nbsp;[&lt;param_1&gt; := '&lt;value&gt;' [, &lt;param_2&gt; := '&lt;value&gt;' [, ...]]]
&nbsp;&nbsp;)
</div>

<p>A create statement defines a relation named <tt>name</tt> with the indicated schema and declares a method for automatically populating/updating rows of that relation.</p>

<p>Each relation may be declared to be either a Stream or a Table:
<ul>
<li>Tables are static data sources.  A table is read in prior to query monitoring, and is assumed to remain constant throughout query evaluation and monitoring.</li>
<li>Streams are dynamic data sources.  Stream updates are read in one tuple at a time as data becomes available, and the query views are refreshed (monitored) after every update.</li>
</ul></p>

<p>The source declaration allows DBToaster (either in the interpreter, or the generated source code) to automatically update the relation.  A source declaration consists of stream and adaptor components.  The stream component defines where data should be read from, and how records in the data are delimited.  At present, DBToaster only supports reading tuples from files. 
</p>

<p>If the same file is referenced multiple times, the file will only be scanned once, and events will be generated in the order in which they appear in the file.
</p>

<p>The adaptor declares how to parse fields out of each record.  See below for documentation on DBToaster's standard adaptors package.
</p>

<p>The source declaration field is optional in source code mode.  User programs may inject updates manually, or specify sources programatically while initializing the DBToaster-generated code.  
</p>

<div class="codeblock">
CREATE STREAM R(a int, b date)
FROM FILE 'data/r.csv' LINE DELIMITED 
CSV (fields := '|')
</div>

<h3 class="code">SELECT</h3>
<center>Declare a query to monitor</center>

<div class="codeblock">
select_statement := 
&nbsp;&nbsp;SELECT &lt;target_1&gt; [, &lt;target_2&gt; [, ...]] 
&nbsp;&nbsp;FROM &lt;source_1&gt; [, &lt;source_2&gt; [, ...]]
&nbsp;&nbsp;WHERE &lt;condition&gt;
&nbsp;&nbsp;[GROUP BY &lt;group_vars&gt;]

target := &lt;expression&gt; [[AS] &lt;target_name&gt;] | * | *.* | &lt;source_name&gt;.*

source := 
&nbsp;&nbsp;&nbsp;&nbsp;&lt;relation_name&gt; [[AS] &lt;source_name&gt;]
&nbsp;&nbsp;|&nbsp;(&lt;select_statement&gt;) [AS] &lt;source_name&gt;
&nbsp;&nbsp;|&nbsp;&lt;source&gt; [NATURAL] JOIN &lt;source&gt; [ON &lt;condition&gt;]

expression := 
&nbsp;&nbsp;&nbsp;&nbsp;(&lt;expression&gt;) |&nbsp;&lt;int&gt; | &lt;float&gt; | '&lt;string&gt;' | &lt;var&gt; | &lt;source&gt;.&lt;var&gt;
&nbsp;&nbsp;|&nbsp;&lt;expression&gt; { + | - | * | / } &lt;expression&gt;
&nbsp;&nbsp;|&nbsp;-&lt;expression&gt;
&nbsp;&nbsp;|&nbsp;(SELECT &lt;expression&gt; FROM ...)
&nbsp;&nbsp;|&nbsp;SUM(&lt;expression&gt;) | COUNT(* | &lt;expression&gt;) | AVG(&lt;expression&gt;)
&nbsp;&nbsp;|&nbsp;&lt;inline_function&gt;([&lt;expression_1&gt; [, &lt;expression_2&gt; [, ...]]])
&nbsp;&nbsp;|&nbsp;DATE('yyyy-mm-dd')

condition := 
&nbsp;&nbsp;&nbsp;&nbsp;(&lt;condition&gt;) | true | false | not (&lt;condition&gt;)
&nbsp;&nbsp;|&nbsp;&lt;expression&gt; { < | <= | > | >= | = | <> } &lt;expression&gt;
&nbsp;&nbsp;|&nbsp;&lt;expression&gt; { < | <= | > | >= | = | <> } { SOME | ALL } &lt;select_statement&gt;
&nbsp;&nbsp;|&nbsp;&lt;condition&gt; AND &lt;condition&gt; | &lt;condition&gt; OR &lt;condition&gt;
&nbsp;&nbsp;|&nbsp;EXISTS &lt;select_statement&gt;
&nbsp;&nbsp;|&nbsp;&lt;expression&gt; BETWEEN &lt;expression&gt; AND &lt;expression&gt;
&nbsp;&nbsp;|&nbsp;&lt;expression&gt; IN &lt;select_statement&gt;

</div>

<p>DBToaster SQL's SELECT operation differs slightly from the SQL-92 standard.
<ul>
<li>UNION, LIMIT, ORDER BY, and HAVING are not supported.</li>
<li>Only the COUNT, SUM, and AVERAGE aggregates are supported.</li>
<li>The only supported types are int, float, date, and string/varchar.</li>
<li>Variable scoping rules are slightly stricter than the SQL standard (you may need to use fully qualified names in some additional cases).</li>
<li>Support for division is limited.  DBToaster does not currently check for, or react to divide by zero errors.  If a result value ever becomes NAN or INFTY, it will no longer be possible to incrementally maintain it.</li>
<li>DBToaster's aggregate functions all produce results when evaluated over empty sets (as opposed to the NULL required by the SQL standard).  The default values for SUM, COUNT, and AVERAGE are all 0.</li>
<li>DBToaster does not allow non-aggregate queries to evaluate to singleton values.  That is, the query<br/>
<tt>SELECT 1 FROM R WHERE R.A = (SELECT A FROM S)</tt><br/>
is a compile-time error in DBToaster, as opposed to simply having the potential to cause a run-time error in SQL92.  An equivalent, valid query would be:<br/>
<tt>SELECT 1 FROM R WHERE R.A IN (SELECT A FROM S)</tt>
</li>
</ul>
</p>

<p>DBToaster maintains query results in the form of either multi-key dictionaries (a.k.a., maps, hashmaps, etc...), or single values.  Each query result is assigned a name based on the query.<p>
<ul>
<li>Non-aggregate queries produce a dictionary named "COUNT".  Keys are formed from the target fields of the SELECT.  Values are the number of times the tuple occurs in the output (i.e., the query includes an implicit group-by COUNT(*) aggregate).</li>
<li>Singleton (non-grouping) aggregate queries produce a single value result for each aggregate target in the SELECT.  The result names are assigned based on the name of each target (i.e., using the name following the optional <tt>AS</tt> clause, or a procedurally generated name otherwise).</li>
<li>Group-by aggregate queries produce a dictionary for each aggregate target.  The non-aggregate (group-by) targets are used as keys for the dictionary (as in non-aggregate queries), and the value is the aggregate value for each group.  The dictionaries are named based on the name of each aggregate target (as for singleton aggregate queries)</li>
</ul></p>

<div class="codeblock">
SELECT SUM(R.A * T.D) FROM R NATURAL JOIN S, T WHERE S.C = T.C;
</div>

<hr/>
<h2>Standard Adaptors Reference</h2>

<p>DBToaster's runtimes currently support the following adaptors:</p>

<ul>
<li> CSV - A simple string-delimited adaptor.  Fields are separated using the delimiter passed in the <b>fields</b> parameter.  If not provided, comma (",") will be used as a default delimiter.<br/>

The optional deletions parameter can be used to generate a single stream of both insertions and deletions.  When set to "true", the input source is assumed to have an extra, leading column.  When the value in this column is 0, the record is treated as a deletion.  When the value is 1, the record is treated as an insertion.<br/>

Fields are parsed based on the type of the corresponding column in the relation.  Ints, floats, and strings are parsed as-is.  Dates are expected to be formatted in the SQL-standard <tt>[yyyy]-[mm]-[dd]</tt> format.<br/>

<div class="codeblock">
    CREATE STREAM R(A int, B int) FROM FILE 'r.dat' 
    LINE DELIMITED CSV (fields := '|');
</div>
</li>

<li> Order book - An adaptor that allows reading in stock trade historical data. It assumes that all the input records obey the following predefined schema: 
<i>&lt;timestamp : float, message_id : int, action_id : char, volume : float, price : float&gt;</i>.  Insertions and deletions are triggered for each record as follows:<br/>
<ul>
  <li>If action_id is 'b', and the orderbook adaptor was instantiated with the parameter book := 'bids', an insertion will be generated for the record.</li>
  <li>If action_id is 'a', and the orderbook adaptor was instantiated with the parameter book := 'asks', an insertion will be generated for the record.</li>
  <li>If action_id is 'd', and the orderbook had previously inserted a record with the same message_id, a deletion will be generated for the record.</li>
</ul>

Records will be instantiated into a relation with schema &lt;T float, ID int, BROKER_ID int, VOLUME float, PRICE float&gt;.  All fields except BROKER_ID are taken directly from the input stream.  BROKER_IDs are assigned in a range from 0 to the integer value of the brokers parameter.  The value of BROKER_ID is assigned randomly, using rand() by default, or deterministically from the value of ID if the deterministic parameter is set to 'yes'.  

<div class="codeblock">
  CREATE STREAM bids(T float, ID int, BROKER_ID int, VOLUME float, PRICE float) 
  FROM FILE 'history.csv' 
  LINE DELIMITED orderbook (book := 'bids', brokers := '10', deterministic := 'yes');
</div>
</ul>


<table border>

<tr><th>Adaptor</th><th>Parameter</th><th>Optional</th><th>Description</th></tr>

<tr>
<td rowspan="2">CSV</td>
<td><div class="code">fields</div></td>
<td>yes</td>
<td>A string delimiter used to extract fields from a record. 
    If not specified, the default value is ','.</td>
</td></tr>

<tr> 
<td><div class="code">deletions</div></td>
<td>yes</td>
<td>If set to "true", use the first field of the input file to distinguish between rows for insertion and rows for deletion.  A 0 in the first column triggers a deletion event.  A 1 in the first column triggers an inertion event.  The first column is stripped off of the record before further parsing is performed.</td>
</tr>

<tr><td rowspan="3">Orderbook</td>
<td><div class="code">action_id</div></td>
<td>no</td>
<td>The value of this parameter may be 'bids' or 'asks', and determines for which orderbook events will be generated.</td>
</tr>

<tr><td><div class="code">brokers</div></td>
<td>yes</td>
<td>The number of brokers to simulate.  By default, 10 brokers will be used.</td>
</tr>

<tr><td><div class="code">deterministic</div></td>
<td>yes</td>
<td>If the value of this parameter is 'yes', broker ids will be generated deterministically based on the message id.  By default, broker ids will be generated randomly using the rand() system call or equivalent.</td>
</tr>

</table>

<hr/>
<h2><a name="optimization">Optional Optimization Features</a></h2>
<dt class="code">-O1</dt>
<ul>
<li> Test for expression equivalence naively. This may result in duplicate maps being created on some queries, but can substantially reduce compile times.
<li> Do not perform functional optimization.
<li> Disable any unnecessary optimizations in the second-stage compiler (e.g., GCC is invoked with no optimization flags).
<li> Use the standard delta rewrite rule to compute deltas of lift expressions.
<li> Avoid pre-evaluating terms that are guaranteed to produce empty relations.
</ul>

<dt class="code">-O2 (default)</dt>
<ul>
<li> Test for expression equivalence by taking into account the sum and product commutativity. This may reduce the number of created maps, but can prolong compile times.
<li> Perform functional optimization.
<li> Compute deltas of lift expressions using an optimized delta rewrite rule.
<li> Disable any unnecessary optimizations in the second-stage compiler (e.g., GCC is invoked with no optimization flags).
</ul>

<dt class="code">-O3</dt>
<ul>
<li> Same as -O2
<li> Attempt to unify entire lifted expressions, and not just lifted variables/values.  This usually produces tighter calculus expressions, but can slow down compilation.
<li> Run an experimental functional optimization that attempts to pull membership tests out of loops.
</ul>

<hr/>
<h2>Debugging Flags</h2>

<h3>Optimization</h3>
<dl>

<dt class="code">CALC-DONT-CREATE-ZEROES</dt>
<dd>Avoid creating empty relation terms during pre-evaluation.  Empty relation terms are aggressively propagated thoughout expressions in which they occur, and may result in expressions that do not need to be incrementally maintained (because they are guaranteed to be always empty).</dd>

<dt class="code">DUMB-LIFT-DELTAS</dt>
<dd>Use the standard delta rewrite rule to compute deltas of lift expressions. By default, the compiler will use an optimized delta rule that can significantly speedup the overall execution time.</dd>

<dt class="code">UNIFY-EXPRESSIONS</dt>
<dd>Attempt to unify entire lifted expressions, and not just lifted variables/values.  This usually produces tighter calculus expressions, but can slow down compilation.</dd>

<dt class="code">WEAK-EXPR-EQUIV</dt>
<dd>Test for expression equivalence naively.  This may result in duplicate maps being created on some queries, but can substantially reduce compile times.</dd>

<dt class="code">IGNORE-DELETES</dt>
<dd>Do not produce delete triggers.  For some queries, this results in plans with fewer maps, but the resultant trigger program will not support deletions.</dd>

<dt class="code">M3TOK3-GENERATE-INIT</dt>
<dd>When activated the map accesses in K3 expressions will contain membership tests and initialization code, otherwise only Lookup operations will get generated.</dd>

<dt class="code">HEURISTICS-ALWAYS-UPDATE</dt>
<dd>In some cases, it is slightly more efficient to re-evaluate parts of the expression tree rather than computing an incremental update.  If this flag is on, the compiler will always compute updates incrementally, regardless.</dd>

<!--
<dt class="code">HEURISTICS-ALWAYS-REPLACE</dt>
<dd>In some cases, it is slightly more efficient to re-evaluate parts of the expression tree rather than computing an incremental update.  If this flag is on, the compiler will always re-evaluate the expression.  This is usually a bad idea to turn on.</dd>
-->

<dt class="code">HEURISTICS-PREFER-REPLACE</dt>
<dd>In some cases, heuristics rules do not provide a clear decision whether it is more efficient to re-evaluate parts of the expression tree than to compute an incremental update. If this flag is on, the compiler will break the tie by re-evaluating the expression; otherwise, it computes updates incrementally.</dd>

<dt class="code">HEURISTICS-IGNORE-FINAL-OPTIMIZATION</dt>
<dd>Do not attempt to optimize materialized expressions further. This is typically only useful to see the exact expression produced by the materializer.</dd>

<dt class="code">HEURISTICS-IGNORE-IVC-OPTIMIZATION</dt>
<dd>Do not apply the heuristic rule that tries to minimize the need for initial value computation. If this flag is on and there is no relation at the root level, lift subexpressions containing irrelevant relations are materialized separately.</dd>

<dt class="code">HEURISTICS-IGNORE-INPUTVAR-RULE</dt>
<dd>Disable the heuristic rule that avoids materialization of expressions with input variables. Final materializations may have input variables. This is typically useful when the size of the domain to be maintained is small.

<dt class="code">EXPRESSIVE-TLQS</dt>
<dd> By default, each toplevel query is materialized as a separate map. If this flag is on, a toplevel query is materialized as a calculus expression rather than a single map. </dd>

<dt class="code">IVC-OPTIMIZE-EXPR</dt>
<dd>Optimize the initial value computation (IVC) expression. This is typically only useful to see the exact expression produced by the IVC module.</dd>

<dt class="code">K3-NO-OPTIMIZE</dt>
<dd>Do not perform functional optimization.</dd>

<dt class="code">K3-NO-CSE-OPT</dt>
<dd>Do not perform common subexpression elimination in the functional stage.</dd>

<dt class="code">K3-NO-BETA-OPT</dt>
<dd>Do not perform beta-reduction in the functional stage.</dd>

<dt class="code">K3-OPTIMIZE-LIFT-UPDATES</dt>
<dd>An experimental (and thus slightly brittle) functional optimization that attempts to pull collection membership tests out of loops wherever possible.</dd>

<dt class="code">ENABLE-PROFILING</dt>
<dd>Enable dbtoaster-specific profiling features in the code generators that support it. See also COMPILE-WITH-PROFILE.</dd>

<dt class="code">IMP-NO-DESUGAR</dt>
<dd>Do not attempt to desugar the imperative code representation.  This is only useful when viewing the imperative representation directly, as desugaring is required by the final stages of the imperative code generators.</dd>

<dt class="code">HASH-STRINGS</dt>
<dd>All strings are replaced by integer hashes of their matching string.  This should make query evalation slightly faster, but is not guaranteed to produce correct results if a hash collision occurs.</dd>

<dt class="code">COMPILE-WITH-GDB</dt>
<dd>For second-stage compilers that support it, request that the second-stage compiler produce a binary with debugging metadata (e.g., compile with GCC's <tt>-g</tt> flag)</dd>

<dt class="code">COMPILE-WITH-PROFILE</dt>
<dd>For second-stage compilers that support it, request that the second-stage compiler produce a binary with profiling support (e.g., compile with GCC's <tt>-pg</tt> flag)</dd>

<dt class="code">COMPILE-WITHOUT-OPT</dt>
<dd>Request that the second-stage compiler disable any unnecessary optimizations (e.g., by default, GCC is invoked with <tt>-O3</tt>, but not if this flag is active).</dd>

</dl>

<h3>K3 Execution Debugging</h3>
<dl>
<dt class="code">LOG-INTERPRETER-UPDATES</dt>
<dd>If running in interpreter mode, print every change that is applied to the database (every PCValueUpdate, PCUpdate, or PCRemove operation that executes).</dd>

<dt class="code">LOG-INTERPRETER-UPDATES</dt>
<dd>If running in interpreter mode, print the full sequence of update events that occur.</dd>

<dt class="code">STEP-INTERPRETER</dt>
<dd>If running in interpreter mode, pause before dispatching each update, and display the update and current state of the database.</dd>

<dt class="code">TRACE-INTERPRETER</dt>
<dd>If running in interpreter mode, print a full trace of the execution path of a K3 program.  At every stage of execution, the expression being evaluated, current environment, and value of the expression are printed.  Traces are printed in order of execution (i.e., depth-first with respect to the K3 syntax tree).  If <tt>STEP-INTERPRETER</tt> is also set, then pause before proceeding to the next step.</dd>

<dt class="code">SINGLE-LINE-MAP-OUTPUT</dt>
<dd>Instruct the interpreter to place all map output on a single line rather than the (more human-readable, but harder to parse) multi-line output format that it uses by default.</dd>

<dt class="code">DBCHECK-ON</dt>
<dd>Validate interpreter output after each stage against a local instance of Postgres.</dd>

</dl>

<h3>Logging</h3>
<dl>
<dt class="code">DETAIL</dt>
<dd>Log errors/warnings/informational messages with detailed information.  This will include the stack trace of the triggering exception (if relevant) and the calculus/k3/etc... expression that triggered the error.</dd>

<dt class="code">LOG-DRIVER</dt>
<dd>Print a quick message before commencing every stage of the compilation process.</dd>

<dt class="code">LOG-SQL-TO-CALC</dt>
<dd>Print detailed progress information during the transformation from SQL to Calculus.</dd>

<dt class="code">LOG-DELTA-DETAIL</dt>
<dd>When computing a delta, print the expression and delta.</dd>

<dt class="code">LOG-CALCOPT-DETAIL</dt>
<dd>Print detailed progress information about the process of optimizing a calculus expression.</dd>

<dt class="code">LOG-CALCOPT-STEPS</dt>
<dd>Print the calculus expression after every optimization step.</dd>

<dt class="code">LOG-LIFT-EQUALITIES</dt>
<dd>Print detailed progress information during application of the LIFT-EQUALITIES optimization.</dd>

<dt class="code">LOG-UNIFY-LIFTS</dt>
<dd>Print detailed progress information during application of the UNIFY-LIFTS optimization.</dd>

<dt class="code">LOG-NESTINGREWRITES-DETAIL</dt>
<dd>Print detailed progress information during application of the NESTINGREWRITES optimization.</dd>

<dt class="code">LOG-FACTORIZE</dt>
<dd>Print detailed progress information while factorizing calculus expressions.</dd>

<dt class="code">LOG-COMPILE-DETAIL</dt>
<dd>Print detailed progress about the compiler's internal planning and datastructure construction process</dd>

<dt class="code">LOG-HEURISTICS-DETAIL</dt>
<dd>Print detailed progress about the process of deciding how to maintain individual datastructures and how to materialize queries.</dd>

<dt class="code">LOG-K3-OPT</dt>
<dd>Print progress information while applying the major K3 optimizations</dd>

<dt class="code">LOG-K3-OPT-DETAIL</dt>
<dd>Print detailed progress information while applying the minor K3 optimizations</dd>

<dt class="code">LOG-SQL, LOG-CALC, LOG-SCHEMA, LOG-PLAN, LOG-M3, LOG-K3</dt>
<dd>After the corresponding phase, print the generated representation before continuing on.</dd>

<dt class="code">LOG-PARSER</dt>
<dd>Enable parser logging in ocamlyacc.  At present, this is the simplest way to track down the cause of parser errors.</dd>

<dt class="code">LOG-GCC</dt>
<dd>Print the full command being used to invoke the second-stage compiler</dd>

</dl>

</div>

</body></html>