DBT-SQL documentation

DBT-SQL is a set of extensions to basic SQL to support compilation via 
DBToaster.

--------------------------------------

SELECT sum(expression) [, sum(expression2)[, ...]] [, gb_term1 [, ...]] 
  FROM r1[, r2[, ...]] 
  WHERE condition
  [GROUP BY gb_term1 [, ...]]

The select statement is unchanged, although the target expression can only have
aggregate and group by terms in it (i.e. Non-aggregate queries are unsupported 
but may be emulated by making all target terms group by terms and adding a 
SUM(1) term).  Currently, only sum is supported.  Count may be emulated by using
SUM(1), and average may be emulated by obtaining a count and a sum and post-
processing to obtain the average.

expression := 
  |  integer
  |  float
  |  string                   # Where string is quoted with 'single quotes'
  |  DATE(date)               # Where date is expressed as YYYY-MM-DD; date may 
                                optionally be 'single quoted'
  |  expression + expression
  |  expression - expression
  |  - expression
  |  expression * expression  # Note that division is NOT supported.
  |  colname
  |  tablename.colname

--------------------------------------

CREATE TABLE r(col1 type[, col2 type[, ...]]) FROM sourceStatement

The first half of the create table statement is unchanged, but since we are 
operating in a streaming context, the compiler needs to know where the data will 
come from.  sourceStatement can be one of four things:

sourceStatement := 
    FILE filename framingStatement adaptorStatement
  | SOCKET [bindAddr] port framingStatement adaptorStatement
  | PIPE pipeCommand framingStatement adaptorStatement
  | POSTGRES [database.]relation(col1 type[, col2 type[, ...]])

FILE and SOCKET are straightforward (SOCKET has little to no support at the 
moment).  PIPE acts like FILE except the data comes from the specified command
rather than a file.  

POSTGRES is a shorthand for a PIPE source that invokes `psql` with the 
appropriate arguments and frame deocder and adaptor.  `psql` is assumed to be in
the path.

framingStatement and adaptorStatement are as follows

framingStatement :=
    FIXEDWIDTH width
 |  LINE DELIMITED
 |  string DELIMITED
 |  VARSIZE
 |  VARSIZE OFFSET offset
 |  VARSIZE OFFSET offset ADJUSTBY adjustby

adaptorStatement := 
    adaptorType [(param1 := val1[, param2 := val2[, ...]])]

framingStatement specifies how input records are separated: FXEDWITDH, LINE 
DELIMITED and string DELIMITED are self-explanatory.  For documentation on 
VARSIZE, see M3.ml

adaptorStatement specifies how fields are to be parsed out of a given record. 
(See libs/ocaml/StandardAdaptors.ml and the following documentation) 

--------------------------------------

The StandardAdaptors Package

To facilitate data processing, the StandardAdaptors package includes a range of
generic, programmable adaptors as part of the processing library.

== CSV ==
(supported in: OCAML)
  eg: CSV( fields := '|', schema := 'int,int,float' )
    ... defines a | delimited list with three fields: Two integers and a float.

Basic record parsing.  Fields are specified as strings in a simple record 
format.

fields: A regular expression that describes how fields are delimited fields in
        each record.  (Required unless 'offsets' is provided)

offsets: A comma-separated list of integers indicating how many bytes each field
         uses.  (Required unless 'fields' is provided)

schema: A comma-separated list of 'int','float','date' or 'hash'.  Indicates the 
        type of each field in the input
        'int'   : The input is parsed as an integer, and represented as a float.
        'float' : The input is parsed as a float.
        'date'  : The input is parsed using SQL date syntax 'YYYY-MM-DD'
        'hash'  : The input is parsed as a string, and hashed into an integer
        If there are more fields than parameters in the type list, the last type 
        will be used as a default for the remainder of the fields.  If the 
        project parameter is present, the field order is post-projection. 
        (Required)

project: A comma-separated list of integers representing field indices (0-based 
         indexing).  If this parameter is present, only the indicated fields 
         will be used, in the same order that they occur in the project 
         parameter. (default: use the fields in the same order they occur)

case: 'upper' or 'lower'; preprocess to change the case of all text in the 
      record. (default: no preprocessing)

substring: A comma-separated list of the form fid,off,len,...; Indicate that 
           field fid should be trimmed (as a string) to the substring 
           [off,off+len).  Multiple substring directives can be chained together
           with commas (default: no trimming)

skiplines: An integer n.  Discard the first n records from the file, as 
           specified by the record delimiter.  Eg: if the record delimiter is
           newline, skip the first n lines.  (default: 0)

trimwhitespace: An empty string.  If this parameter is present, whitespace 
                at the front and end of each field is removed prior to parsing.
                (default: no trimming)

eventtype: 'insert' or 'delete'; Specify that the adaptor generates purely 
           insert or delete events. (default: insert, see events below)

events: A comma-separated list of 'string:insert' or 'string:delete' entries.  
        If specified, the leading field of the record will be removed and used
        as an event type discriminator; It will be compared to all entries in
        the parameters, and the record will be treated as the corresponding 
        event.