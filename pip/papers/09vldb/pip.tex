\documentclass{vldb}

\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{subfigure}
%\usepackage{epsfig}
%\usepackage{epic}
%\usepackage{eepic}
%\usepackage{xspace}
%\usepackage{pstricks}
%\usepackage{pst-doc}
%\usepackage{pst-func,pst-math,pst-xkey}

\def\punto{$\hspace*{\fill}\Box$}
\newcommand{\nop}[1]{}
\newcommand{\tuple}[1]{{\langle#1\rangle}}
\def\lBrack{\lbrack\!\lbrack}
\def\rBrack{\rbrack\!\rbrack}
\newcommand{\Bracks}[1]{\lBrack#1\rBrack}


\leftmargini 2.9ex


\newtheorem{theorem}{Theorem}[section]
\newtheorem{metatheorem}{Metatheorem}[section]
\newtheorem{example}[theorem]{Example}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{proviso}[theorem]{Proviso}
\newtheorem{todo}[theorem]{ToDo}

%\addtolength{\textwidth}{1in}
%\addtolength{\oddsidemargin}{-0.5in}
%\addtolength{\evensidemargin}{-0.5in}
%\addtolength{\textheight}{1.5in}
%\addtolength{\topmargin}{-1in}


\title{PIP: A Database System for Great and Small Expectations%
% Efficiently Computing
\thanks{The
system is named after Philip Pirrip, nicknamed Pip, the protagonist of
Charles Dickens' novel Great Expectations.}}


%\numberofauthors{1}

\author{\alignauthor Oliver Kennedy and Christoph Koch\\
\affaddr{Department of Computer Science} \\
\affaddr{Cornell University, Ithaca, NY, USA} \\
\email{\{okennedy, koch\}@cs.cornell.edu}}

\date{}
\toappear{}

\begin{document}


\numberofauthors{2}


\maketitle



\begin{abstract}
Estimation via sampling out of highly selective join queries is a well known problem, most notably in online aggregation.  Without goal-directed sampling strategies, samples falling outside of the selection constraints lower estimation efficiency at best, and cause inaccurate estimates at worst.  This problem appears in general probabilistic database systems, where query processing is tightly coupled with sampling.  By committing to a set of samples before evaluating the query, the engine wastes effort on samples that will be discarded, query processing that may need to be repeated, or unnecessarily large numbers of samples.  

We describe PIP, a probabilistic database system that uses symbolic representations of probabilistic data to defer computation of expectations, moments, and other statistical measures until the expression to be measured is fully known.  This approach is sufficiently general to admit both continuous and discrete distributions.  Moreover, deferring sampling enables a broad range of goal-oriented sampling (as well as exact) integration techniques for computing statistical measures, allows the selection of the integration strategy most appropriate to the expression being measured, and reduces the amount of work required.  

We demonstrate the effectiveness of this approach by showing that even straightforward algorithms can make use of this information.  These algorithms have a profoundly positive impact on the efficiency and accuracy of expectation computations, particularly in the case of highly selective join queries.
\end{abstract}



\section{Introduction}
\label{sec:introduction}
\input{sec_introduction.tex}

\section{Probabilistic C-Tables}
\label{sec:background}
\input{sec_background.tex}

\section{Monte Carlo Sampling and Integration}
\label{sec:sampling}
\input{sec_sampling.tex}

\section{Design of the PIP System}
\label{sec:design}
\input{sec_design.tex}

\section{Implementation}
\label{sec:implementation}
\input{sec_implementation.tex}

\section{Evaluation}
\label{sec:evaluation}
\input{sec_evaluation.tex}


\section{Conclusion}

We have shown that symbolic representations of uncertainty like C-Tables can be used to make the computation of expectations, moments, and other statistical measures in probabilistic databases more accurate and more efficient.  The availability of the expression being measured enables a broad range of sampling techniques that rely on this information and allows more effective selection of the appropriate technique for a given expression.

We have shown that the use of symbolic representations can be, even with straightforward algorithms, exploited to significantly reduce query processing time, and significantly improve query accuracy for a wide range of queries.  For the remaining queries, we have shown that the overhead created by the symbolic representation has only a negligible impact on query processing time.  This, combined with PIP's extensibility, make it a powerful platform for evaluating a wide range of queries over uncertain data.

\begin{small}
\bibliographystyle{abbrv}
\bibliography{bibtex}
\end{small}


\end{document}
