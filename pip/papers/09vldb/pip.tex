\documentclass{vldb}

\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{subfigure}
%\usepackage{epsfig}
%\usepackage{epic}
%\usepackage{eepic}
%\usepackage{xspace}
%\usepackage{pstricks}
%\usepackage{pst-doc}
%\usepackage{pst-func,pst-math,pst-xkey}

\def\punto{$\hspace*{\fill}\Box$}
\newcommand{\nop}[1]{}
\newcommand{\tuple}[1]{{\langle#1\rangle}}
\def\lBrack{\lbrack\!\lbrack}
\def\rBrack{\rbrack\!\rbrack}
\newcommand{\Bracks}[1]{\lBrack#1\rBrack}


\leftmargini 2.9ex


\newtheorem{theorem}{Theorem}[section]
\newtheorem{metatheorem}{Metatheorem}[section]
\newtheorem{example}[theorem]{Example}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{proviso}[theorem]{Proviso}
\newtheorem{todo}[theorem]{ToDo}

%\addtolength{\textwidth}{1in}
%\addtolength{\oddsidemargin}{-0.5in}
%\addtolength{\evensidemargin}{-0.5in}
%\addtolength{\textheight}{1.5in}
%\addtolength{\topmargin}{-1in}


\title{PIP: A Database System for Great and Small Expectations%
% Efficiently Computing
\thanks{The
system is named after Philip Pirrip, nicknamed Pip, the protagonist of
Charles Dickens' novel Great Expectations.}}


\author{Oliver Kennedy and Christoph Koch\\
Department of Computer Science \\
Cornell University, Ithaca, NY, USA \\
\{okennedy, koch\}@cs.cornell.edu}

\date{}


\begin{document}


\numberofauthors{2}


\maketitle



\begin{abstract}
We describe PIP, a probabilistic database system
that combines the strengths of
recent discrete systems such as MystiQ and MayBMS with the generality of
the Monte-Carlo approach of MCDB. It supports both discrete and
continuous probability distributions, powerful correlations definable
by queries, expectations of aggregates and distinct-aggregates with or
without  group-by,  and the computation of confidences.
%
PIP uses c-tables to delay and minimize the amount of sampling work required.
We study Monte-Carlo sampling and integration and
present a Karp-Luby style importance
sampling algorithm for continuous distributions.
This technique is essential
in scenarios where very small probabilities have to be approximated to a small
relative error, as is often the case for the computation of conditional
probabilities (as ratios of probabilities).
%
We also provide experimental evidence for the competitiveness
of our approach, comparing PIP with a reimplementation of the
refined sample-first approach taken by MCDB. 
\end{abstract}



\section{Introduction}
\label{sec:introduction}
\input{sec_introduction.tex}

\section{Probabilistic C-Tables}
\label{sec:background}
\input{sec_background.tex}

\section{Monte Carlo Sampling and Integration}
\label{sec:sampling}
\input{sec_sampling.tex}

\section{Design of the PIP System}
\label{sec:design}
\input{sec_design.tex}

\section{Implementation}
\label{sec:implementation}
\input{sec_implementation.tex}

\section{Evaluation}
\label{sec:evaluation}
\input{sec_evaluation.tex}


\section{Conclusion}

We have shown that it is possible to apply the c-tables approach to probabilistic databases with only minimal overhead, even when it is used to represent arbitrary variable distributions.  The additional information provided by the c-table adds a degree of flexibility that allows PIP to outperform Sample-First approaches in a number of instances.

\begin{small}
\bibliographystyle{abbrv}
\bibliography{bibtex}
\end{small}


\end{document}
